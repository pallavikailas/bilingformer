{
  "best_metric": 0.5631,
  "best_model_checkpoint": "google/mt5-base-finetuned/checkpoint-20000",
  "epoch": 150.37593984962405,
  "eval_steps": 20000,
  "global_step": 20000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19,
      "learning_rate": 0.0005994360902255638,
      "loss": 14.5459,
      "step": 25
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0005988721804511277,
      "loss": 6.7611,
      "step": 50
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0005983082706766917,
      "loss": 5.4806,
      "step": 75
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0005977443609022556,
      "loss": 4.3589,
      "step": 100
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0005971804511278195,
      "loss": 3.9259,
      "step": 125
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0005966165413533835,
      "loss": 3.6301,
      "step": 150
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0005960526315789474,
      "loss": 3.4432,
      "step": 175
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0005954887218045112,
      "loss": 3.5057,
      "step": 200
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0005949248120300752,
      "loss": 3.3619,
      "step": 225
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0005943609022556391,
      "loss": 3.3555,
      "step": 250
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000593796992481203,
      "loss": 3.2491,
      "step": 275
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0005932330827067669,
      "loss": 3.1187,
      "step": 300
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005926691729323308,
      "loss": 3.0884,
      "step": 325
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005921052631578947,
      "loss": 3.1539,
      "step": 350
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005915413533834586,
      "loss": 3.1361,
      "step": 375
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0005909774436090225,
      "loss": 3.0634,
      "step": 400
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0005904135338345865,
      "loss": 2.9624,
      "step": 425
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0005898496240601504,
      "loss": 2.8965,
      "step": 450
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0005892857142857142,
      "loss": 2.9661,
      "step": 475
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0005887218045112781,
      "loss": 2.9108,
      "step": 500
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0005881578947368421,
      "loss": 2.9176,
      "step": 525
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.000587593984962406,
      "loss": 2.786,
      "step": 550
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0005870300751879699,
      "loss": 2.757,
      "step": 575
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.0005864661654135338,
      "loss": 2.7941,
      "step": 600
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.0005859022556390977,
      "loss": 2.7696,
      "step": 625
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.0005853383458646616,
      "loss": 2.7931,
      "step": 650
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.0005847744360902255,
      "loss": 2.6426,
      "step": 675
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.0005842105263157894,
      "loss": 2.6249,
      "step": 700
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.0005836466165413534,
      "loss": 2.5888,
      "step": 725
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.0005830827067669172,
      "loss": 2.6865,
      "step": 750
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.0005825187969924811,
      "loss": 2.602,
      "step": 775
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.0005819548872180451,
      "loss": 2.6323,
      "step": 800
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.000581390977443609,
      "loss": 2.4117,
      "step": 825
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.0005808270676691729,
      "loss": 2.4798,
      "step": 850
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.0005802631578947368,
      "loss": 2.4913,
      "step": 875
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.0005796992481203007,
      "loss": 2.4834,
      "step": 900
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.0005791353383458646,
      "loss": 2.5341,
      "step": 925
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.0005785714285714285,
      "loss": 2.3568,
      "step": 950
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.0005780075187969924,
      "loss": 2.3086,
      "step": 975
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.0005774436090225563,
      "loss": 2.3101,
      "step": 1000
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.0005768796992481202,
      "loss": 2.357,
      "step": 1025
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.0005763157894736841,
      "loss": 2.3644,
      "step": 1050
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.0005757518796992481,
      "loss": 2.3085,
      "step": 1075
    },
    {
      "epoch": 8.27,
      "learning_rate": 0.000575187969924812,
      "loss": 2.1683,
      "step": 1100
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.0005746240601503759,
      "loss": 2.2059,
      "step": 1125
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.0005740601503759398,
      "loss": 2.228,
      "step": 1150
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.0005734962406015037,
      "loss": 2.199,
      "step": 1175
    },
    {
      "epoch": 9.02,
      "learning_rate": 0.0005729323308270676,
      "loss": 2.2193,
      "step": 1200
    },
    {
      "epoch": 9.21,
      "learning_rate": 0.0005723684210526315,
      "loss": 2.0583,
      "step": 1225
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.0005718045112781954,
      "loss": 2.0982,
      "step": 1250
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.0005712406015037593,
      "loss": 2.135,
      "step": 1275
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.0005706766917293232,
      "loss": 2.1613,
      "step": 1300
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.0005701127819548871,
      "loss": 2.1486,
      "step": 1325
    },
    {
      "epoch": 10.15,
      "learning_rate": 0.0005695488721804511,
      "loss": 1.9729,
      "step": 1350
    },
    {
      "epoch": 10.34,
      "learning_rate": 0.000568984962406015,
      "loss": 1.9827,
      "step": 1375
    },
    {
      "epoch": 10.53,
      "learning_rate": 0.0005684210526315788,
      "loss": 1.9927,
      "step": 1400
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.0005678571428571427,
      "loss": 2.0131,
      "step": 1425
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.0005672932330827067,
      "loss": 2.0198,
      "step": 1450
    },
    {
      "epoch": 11.09,
      "learning_rate": 0.0005667293233082706,
      "loss": 1.98,
      "step": 1475
    },
    {
      "epoch": 11.28,
      "learning_rate": 0.0005661654135338345,
      "loss": 1.856,
      "step": 1500
    },
    {
      "epoch": 11.47,
      "learning_rate": 0.0005656015037593984,
      "loss": 1.8338,
      "step": 1525
    },
    {
      "epoch": 11.65,
      "learning_rate": 0.0005650375939849623,
      "loss": 1.9213,
      "step": 1550
    },
    {
      "epoch": 11.84,
      "learning_rate": 0.0005644736842105262,
      "loss": 1.9151,
      "step": 1575
    },
    {
      "epoch": 12.03,
      "learning_rate": 0.0005639097744360902,
      "loss": 1.9012,
      "step": 1600
    },
    {
      "epoch": 12.22,
      "learning_rate": 0.000563345864661654,
      "loss": 1.7301,
      "step": 1625
    },
    {
      "epoch": 12.41,
      "learning_rate": 0.0005627819548872181,
      "loss": 1.7566,
      "step": 1650
    },
    {
      "epoch": 12.59,
      "learning_rate": 0.0005622180451127819,
      "loss": 1.8175,
      "step": 1675
    },
    {
      "epoch": 12.78,
      "learning_rate": 0.0005616541353383458,
      "loss": 1.8089,
      "step": 1700
    },
    {
      "epoch": 12.97,
      "learning_rate": 0.0005610902255639098,
      "loss": 1.8097,
      "step": 1725
    },
    {
      "epoch": 13.16,
      "learning_rate": 0.0005605263157894737,
      "loss": 1.683,
      "step": 1750
    },
    {
      "epoch": 13.35,
      "learning_rate": 0.0005599624060150376,
      "loss": 1.6566,
      "step": 1775
    },
    {
      "epoch": 13.53,
      "learning_rate": 0.0005593984962406015,
      "loss": 1.7308,
      "step": 1800
    },
    {
      "epoch": 13.72,
      "learning_rate": 0.0005588345864661654,
      "loss": 1.7513,
      "step": 1825
    },
    {
      "epoch": 13.91,
      "learning_rate": 0.0005582706766917293,
      "loss": 1.7369,
      "step": 1850
    },
    {
      "epoch": 14.1,
      "learning_rate": 0.0005577067669172932,
      "loss": 1.641,
      "step": 1875
    },
    {
      "epoch": 14.29,
      "learning_rate": 0.0005571428571428571,
      "loss": 1.6094,
      "step": 1900
    },
    {
      "epoch": 14.47,
      "learning_rate": 0.0005565789473684211,
      "loss": 1.6553,
      "step": 1925
    },
    {
      "epoch": 14.66,
      "learning_rate": 0.0005560150375939849,
      "loss": 1.7124,
      "step": 1950
    },
    {
      "epoch": 14.85,
      "learning_rate": 0.0005554511278195488,
      "loss": 1.7021,
      "step": 1975
    },
    {
      "epoch": 15.04,
      "learning_rate": 0.0005548872180451128,
      "loss": 1.6357,
      "step": 2000
    },
    {
      "epoch": 15.23,
      "learning_rate": 0.0005543233082706767,
      "loss": 1.5174,
      "step": 2025
    },
    {
      "epoch": 15.41,
      "learning_rate": 0.0005537593984962406,
      "loss": 1.5228,
      "step": 2050
    },
    {
      "epoch": 15.6,
      "learning_rate": 0.0005531954887218045,
      "loss": 1.5726,
      "step": 2075
    },
    {
      "epoch": 15.79,
      "learning_rate": 0.0005526315789473684,
      "loss": 1.5876,
      "step": 2100
    },
    {
      "epoch": 15.98,
      "learning_rate": 0.0005520676691729323,
      "loss": 1.6146,
      "step": 2125
    },
    {
      "epoch": 16.17,
      "learning_rate": 0.0005515037593984962,
      "loss": 1.4404,
      "step": 2150
    },
    {
      "epoch": 16.35,
      "learning_rate": 0.0005509398496240601,
      "loss": 1.4163,
      "step": 2175
    },
    {
      "epoch": 16.54,
      "learning_rate": 0.000550375939849624,
      "loss": 1.4661,
      "step": 2200
    },
    {
      "epoch": 16.73,
      "learning_rate": 0.0005498120300751879,
      "loss": 1.5005,
      "step": 2225
    },
    {
      "epoch": 16.92,
      "learning_rate": 0.0005492481203007518,
      "loss": 1.5271,
      "step": 2250
    },
    {
      "epoch": 17.11,
      "learning_rate": 0.0005486842105263158,
      "loss": 1.4117,
      "step": 2275
    },
    {
      "epoch": 17.29,
      "learning_rate": 0.0005481203007518797,
      "loss": 1.3936,
      "step": 2300
    },
    {
      "epoch": 17.48,
      "learning_rate": 0.0005475563909774436,
      "loss": 1.424,
      "step": 2325
    },
    {
      "epoch": 17.67,
      "learning_rate": 0.0005469924812030074,
      "loss": 1.4085,
      "step": 2350
    },
    {
      "epoch": 17.86,
      "learning_rate": 0.0005464285714285714,
      "loss": 1.4467,
      "step": 2375
    },
    {
      "epoch": 18.05,
      "learning_rate": 0.0005458646616541353,
      "loss": 1.3988,
      "step": 2400
    },
    {
      "epoch": 18.23,
      "learning_rate": 0.0005453007518796992,
      "loss": 1.2595,
      "step": 2425
    },
    {
      "epoch": 18.42,
      "learning_rate": 0.0005447368421052631,
      "loss": 1.3383,
      "step": 2450
    },
    {
      "epoch": 18.61,
      "learning_rate": 0.000544172932330827,
      "loss": 1.3535,
      "step": 2475
    },
    {
      "epoch": 18.8,
      "learning_rate": 0.0005436090225563909,
      "loss": 1.4182,
      "step": 2500
    },
    {
      "epoch": 18.98,
      "learning_rate": 0.0005430451127819548,
      "loss": 1.4155,
      "step": 2525
    },
    {
      "epoch": 19.17,
      "learning_rate": 0.0005424812030075187,
      "loss": 1.2275,
      "step": 2550
    },
    {
      "epoch": 19.36,
      "learning_rate": 0.0005419172932330827,
      "loss": 1.2697,
      "step": 2575
    },
    {
      "epoch": 19.55,
      "learning_rate": 0.0005413533834586465,
      "loss": 1.2651,
      "step": 2600
    },
    {
      "epoch": 19.74,
      "learning_rate": 0.0005407894736842104,
      "loss": 1.2723,
      "step": 2625
    },
    {
      "epoch": 19.92,
      "learning_rate": 0.0005402255639097744,
      "loss": 1.296,
      "step": 2650
    },
    {
      "epoch": 20.11,
      "learning_rate": 0.0005396616541353383,
      "loss": 1.1998,
      "step": 2675
    },
    {
      "epoch": 20.3,
      "learning_rate": 0.0005390977443609022,
      "loss": 1.1577,
      "step": 2700
    },
    {
      "epoch": 20.49,
      "learning_rate": 0.0005385338345864661,
      "loss": 1.1534,
      "step": 2725
    },
    {
      "epoch": 20.68,
      "learning_rate": 0.00053796992481203,
      "loss": 1.1792,
      "step": 2750
    },
    {
      "epoch": 20.86,
      "learning_rate": 0.0005374060150375939,
      "loss": 1.1802,
      "step": 2775
    },
    {
      "epoch": 21.05,
      "learning_rate": 0.0005368421052631578,
      "loss": 1.1683,
      "step": 2800
    },
    {
      "epoch": 21.24,
      "learning_rate": 0.0005362781954887217,
      "loss": 1.0906,
      "step": 2825
    },
    {
      "epoch": 21.43,
      "learning_rate": 0.0005357142857142857,
      "loss": 1.0939,
      "step": 2850
    },
    {
      "epoch": 21.62,
      "learning_rate": 0.0005351503759398495,
      "loss": 1.1283,
      "step": 2875
    },
    {
      "epoch": 21.8,
      "learning_rate": 0.0005345864661654134,
      "loss": 1.1382,
      "step": 2900
    },
    {
      "epoch": 21.99,
      "learning_rate": 0.0005340225563909774,
      "loss": 1.1467,
      "step": 2925
    },
    {
      "epoch": 22.18,
      "learning_rate": 0.0005334586466165413,
      "loss": 1.0497,
      "step": 2950
    },
    {
      "epoch": 22.37,
      "learning_rate": 0.0005328947368421052,
      "loss": 1.0461,
      "step": 2975
    },
    {
      "epoch": 22.56,
      "learning_rate": 0.0005323308270676691,
      "loss": 1.0697,
      "step": 3000
    },
    {
      "epoch": 22.74,
      "learning_rate": 0.000531766917293233,
      "loss": 1.0741,
      "step": 3025
    },
    {
      "epoch": 22.93,
      "learning_rate": 0.000531203007518797,
      "loss": 1.098,
      "step": 3050
    },
    {
      "epoch": 23.12,
      "learning_rate": 0.0005306390977443608,
      "loss": 1.0403,
      "step": 3075
    },
    {
      "epoch": 23.31,
      "learning_rate": 0.0005300751879699248,
      "loss": 1.0004,
      "step": 3100
    },
    {
      "epoch": 23.5,
      "learning_rate": 0.0005295112781954888,
      "loss": 1.0132,
      "step": 3125
    },
    {
      "epoch": 23.68,
      "learning_rate": 0.0005289473684210526,
      "loss": 1.0383,
      "step": 3150
    },
    {
      "epoch": 23.87,
      "learning_rate": 0.0005283834586466165,
      "loss": 1.051,
      "step": 3175
    },
    {
      "epoch": 24.06,
      "learning_rate": 0.0005278195488721805,
      "loss": 1.0288,
      "step": 3200
    },
    {
      "epoch": 24.25,
      "learning_rate": 0.0005272556390977444,
      "loss": 0.9544,
      "step": 3225
    },
    {
      "epoch": 24.44,
      "learning_rate": 0.0005266917293233083,
      "loss": 0.9888,
      "step": 3250
    },
    {
      "epoch": 24.62,
      "learning_rate": 0.0005261278195488721,
      "loss": 0.9914,
      "step": 3275
    },
    {
      "epoch": 24.81,
      "learning_rate": 0.0005255639097744361,
      "loss": 1.01,
      "step": 3300
    },
    {
      "epoch": 25.0,
      "learning_rate": 0.000525,
      "loss": 1.0137,
      "step": 3325
    },
    {
      "epoch": 25.19,
      "learning_rate": 0.0005244360902255639,
      "loss": 0.9005,
      "step": 3350
    },
    {
      "epoch": 25.38,
      "learning_rate": 0.0005238721804511278,
      "loss": 0.9346,
      "step": 3375
    },
    {
      "epoch": 25.56,
      "learning_rate": 0.0005233082706766917,
      "loss": 0.9363,
      "step": 3400
    },
    {
      "epoch": 25.75,
      "learning_rate": 0.0005227443609022556,
      "loss": 0.9795,
      "step": 3425
    },
    {
      "epoch": 25.94,
      "learning_rate": 0.0005221804511278195,
      "loss": 0.9982,
      "step": 3450
    },
    {
      "epoch": 26.13,
      "learning_rate": 0.0005216165413533834,
      "loss": 0.9279,
      "step": 3475
    },
    {
      "epoch": 26.32,
      "learning_rate": 0.0005210526315789474,
      "loss": 0.886,
      "step": 3500
    },
    {
      "epoch": 26.5,
      "learning_rate": 0.0005204887218045112,
      "loss": 0.889,
      "step": 3525
    },
    {
      "epoch": 26.69,
      "learning_rate": 0.0005199248120300751,
      "loss": 0.9199,
      "step": 3550
    },
    {
      "epoch": 26.88,
      "learning_rate": 0.0005193609022556391,
      "loss": 0.9423,
      "step": 3575
    },
    {
      "epoch": 27.07,
      "learning_rate": 0.000518796992481203,
      "loss": 0.9062,
      "step": 3600
    },
    {
      "epoch": 27.26,
      "learning_rate": 0.0005182330827067669,
      "loss": 0.8489,
      "step": 3625
    },
    {
      "epoch": 27.44,
      "learning_rate": 0.0005176691729323308,
      "loss": 0.8884,
      "step": 3650
    },
    {
      "epoch": 27.63,
      "learning_rate": 0.0005171052631578947,
      "loss": 0.8918,
      "step": 3675
    },
    {
      "epoch": 27.82,
      "learning_rate": 0.0005165413533834586,
      "loss": 0.8888,
      "step": 3700
    },
    {
      "epoch": 28.01,
      "learning_rate": 0.0005159774436090225,
      "loss": 0.8981,
      "step": 3725
    },
    {
      "epoch": 28.2,
      "learning_rate": 0.0005154135338345864,
      "loss": 0.8242,
      "step": 3750
    },
    {
      "epoch": 28.38,
      "learning_rate": 0.0005148496240601504,
      "loss": 0.8396,
      "step": 3775
    },
    {
      "epoch": 28.57,
      "learning_rate": 0.0005142857142857142,
      "loss": 0.8489,
      "step": 3800
    },
    {
      "epoch": 28.76,
      "learning_rate": 0.0005137218045112781,
      "loss": 0.8555,
      "step": 3825
    },
    {
      "epoch": 28.95,
      "learning_rate": 0.0005131578947368421,
      "loss": 0.8773,
      "step": 3850
    },
    {
      "epoch": 29.14,
      "learning_rate": 0.000512593984962406,
      "loss": 0.8301,
      "step": 3875
    },
    {
      "epoch": 29.32,
      "learning_rate": 0.0005120300751879699,
      "loss": 0.8022,
      "step": 3900
    },
    {
      "epoch": 29.51,
      "learning_rate": 0.0005114661654135338,
      "loss": 0.8314,
      "step": 3925
    },
    {
      "epoch": 29.7,
      "learning_rate": 0.0005109022556390977,
      "loss": 0.8422,
      "step": 3950
    },
    {
      "epoch": 29.89,
      "learning_rate": 0.0005103383458646616,
      "loss": 0.8429,
      "step": 3975
    },
    {
      "epoch": 30.08,
      "learning_rate": 0.0005097744360902255,
      "loss": 0.8263,
      "step": 4000
    },
    {
      "epoch": 30.26,
      "learning_rate": 0.0005092105263157894,
      "loss": 0.7849,
      "step": 4025
    },
    {
      "epoch": 30.45,
      "learning_rate": 0.0005086466165413534,
      "loss": 0.7967,
      "step": 4050
    },
    {
      "epoch": 30.64,
      "learning_rate": 0.0005080827067669172,
      "loss": 0.7997,
      "step": 4075
    },
    {
      "epoch": 30.83,
      "learning_rate": 0.0005075187969924811,
      "loss": 0.8179,
      "step": 4100
    },
    {
      "epoch": 31.02,
      "learning_rate": 0.0005069548872180451,
      "loss": 0.8146,
      "step": 4125
    },
    {
      "epoch": 31.2,
      "learning_rate": 0.000506390977443609,
      "loss": 0.7473,
      "step": 4150
    },
    {
      "epoch": 31.39,
      "learning_rate": 0.0005058270676691729,
      "loss": 0.7498,
      "step": 4175
    },
    {
      "epoch": 31.58,
      "learning_rate": 0.0005052631578947367,
      "loss": 0.7825,
      "step": 4200
    },
    {
      "epoch": 31.77,
      "learning_rate": 0.0005046992481203007,
      "loss": 0.7868,
      "step": 4225
    },
    {
      "epoch": 31.95,
      "learning_rate": 0.0005041353383458646,
      "loss": 0.7969,
      "step": 4250
    },
    {
      "epoch": 32.14,
      "learning_rate": 0.0005035714285714285,
      "loss": 0.7308,
      "step": 4275
    },
    {
      "epoch": 32.33,
      "learning_rate": 0.0005030075187969924,
      "loss": 0.7317,
      "step": 4300
    },
    {
      "epoch": 32.52,
      "learning_rate": 0.0005024436090225563,
      "loss": 0.7402,
      "step": 4325
    },
    {
      "epoch": 32.71,
      "learning_rate": 0.0005018796992481202,
      "loss": 0.7765,
      "step": 4350
    },
    {
      "epoch": 32.89,
      "learning_rate": 0.0005013157894736841,
      "loss": 0.7745,
      "step": 4375
    },
    {
      "epoch": 33.08,
      "learning_rate": 0.000500751879699248,
      "loss": 0.7465,
      "step": 4400
    },
    {
      "epoch": 33.27,
      "learning_rate": 0.000500187969924812,
      "loss": 0.6941,
      "step": 4425
    },
    {
      "epoch": 33.46,
      "learning_rate": 0.0004996240601503759,
      "loss": 0.7116,
      "step": 4450
    },
    {
      "epoch": 33.65,
      "learning_rate": 0.0004990601503759397,
      "loss": 0.7327,
      "step": 4475
    },
    {
      "epoch": 33.83,
      "learning_rate": 0.0004984962406015037,
      "loss": 0.7289,
      "step": 4500
    },
    {
      "epoch": 34.02,
      "learning_rate": 0.0004979323308270676,
      "loss": 0.7331,
      "step": 4525
    },
    {
      "epoch": 34.21,
      "learning_rate": 0.0004973684210526315,
      "loss": 0.6591,
      "step": 4550
    },
    {
      "epoch": 34.4,
      "learning_rate": 0.0004968045112781954,
      "loss": 0.6843,
      "step": 4575
    },
    {
      "epoch": 34.59,
      "learning_rate": 0.0004962406015037594,
      "loss": 0.6977,
      "step": 4600
    },
    {
      "epoch": 34.77,
      "learning_rate": 0.0004956766917293233,
      "loss": 0.703,
      "step": 4625
    },
    {
      "epoch": 34.96,
      "learning_rate": 0.0004951127819548872,
      "loss": 0.719,
      "step": 4650
    },
    {
      "epoch": 35.15,
      "learning_rate": 0.000494548872180451,
      "loss": 0.6435,
      "step": 4675
    },
    {
      "epoch": 35.34,
      "learning_rate": 0.0004939849624060151,
      "loss": 0.6486,
      "step": 4700
    },
    {
      "epoch": 35.53,
      "learning_rate": 0.0004934210526315789,
      "loss": 0.6619,
      "step": 4725
    },
    {
      "epoch": 35.71,
      "learning_rate": 0.0004928571428571428,
      "loss": 0.6822,
      "step": 4750
    },
    {
      "epoch": 35.9,
      "learning_rate": 0.0004922932330827068,
      "loss": 0.6829,
      "step": 4775
    },
    {
      "epoch": 36.09,
      "learning_rate": 0.0004917293233082707,
      "loss": 0.6544,
      "step": 4800
    },
    {
      "epoch": 36.28,
      "learning_rate": 0.0004911654135338346,
      "loss": 0.6191,
      "step": 4825
    },
    {
      "epoch": 36.47,
      "learning_rate": 0.0004906015037593985,
      "loss": 0.6314,
      "step": 4850
    },
    {
      "epoch": 36.65,
      "learning_rate": 0.0004900375939849624,
      "loss": 0.6413,
      "step": 4875
    },
    {
      "epoch": 36.84,
      "learning_rate": 0.0004894736842105263,
      "loss": 0.6474,
      "step": 4900
    },
    {
      "epoch": 37.03,
      "learning_rate": 0.0004889097744360902,
      "loss": 0.6502,
      "step": 4925
    },
    {
      "epoch": 37.22,
      "learning_rate": 0.0004883458646616541,
      "loss": 0.5874,
      "step": 4950
    },
    {
      "epoch": 37.41,
      "learning_rate": 0.00048778195488721803,
      "loss": 0.606,
      "step": 4975
    },
    {
      "epoch": 37.59,
      "learning_rate": 0.0004872180451127819,
      "loss": 0.6158,
      "step": 5000
    },
    {
      "epoch": 37.78,
      "learning_rate": 0.00048665413533834583,
      "loss": 0.6233,
      "step": 5025
    },
    {
      "epoch": 37.97,
      "learning_rate": 0.00048609022556390973,
      "loss": 0.6299,
      "step": 5050
    },
    {
      "epoch": 38.16,
      "learning_rate": 0.00048552631578947363,
      "loss": 0.5795,
      "step": 5075
    },
    {
      "epoch": 38.35,
      "learning_rate": 0.0004849624060150376,
      "loss": 0.5768,
      "step": 5100
    },
    {
      "epoch": 38.53,
      "learning_rate": 0.00048439849624060143,
      "loss": 0.5921,
      "step": 5125
    },
    {
      "epoch": 38.72,
      "learning_rate": 0.00048383458646616533,
      "loss": 0.603,
      "step": 5150
    },
    {
      "epoch": 38.91,
      "learning_rate": 0.0004832706766917293,
      "loss": 0.6172,
      "step": 5175
    },
    {
      "epoch": 39.1,
      "learning_rate": 0.0004827067669172932,
      "loss": 0.5787,
      "step": 5200
    },
    {
      "epoch": 39.29,
      "learning_rate": 0.00048214285714285715,
      "loss": 0.5537,
      "step": 5225
    },
    {
      "epoch": 39.47,
      "learning_rate": 0.00048157894736842105,
      "loss": 0.5606,
      "step": 5250
    },
    {
      "epoch": 39.66,
      "learning_rate": 0.0004810150375939849,
      "loss": 0.577,
      "step": 5275
    },
    {
      "epoch": 39.85,
      "learning_rate": 0.0004804511278195488,
      "loss": 0.5829,
      "step": 5300
    },
    {
      "epoch": 40.04,
      "learning_rate": 0.00047988721804511275,
      "loss": 0.5686,
      "step": 5325
    },
    {
      "epoch": 40.23,
      "learning_rate": 0.00047932330827067665,
      "loss": 0.5283,
      "step": 5350
    },
    {
      "epoch": 40.41,
      "learning_rate": 0.0004787593984962406,
      "loss": 0.5368,
      "step": 5375
    },
    {
      "epoch": 40.6,
      "learning_rate": 0.00047819548872180445,
      "loss": 0.5463,
      "step": 5400
    },
    {
      "epoch": 40.79,
      "learning_rate": 0.00047763157894736835,
      "loss": 0.5591,
      "step": 5425
    },
    {
      "epoch": 40.98,
      "learning_rate": 0.0004770676691729323,
      "loss": 0.563,
      "step": 5450
    },
    {
      "epoch": 41.17,
      "learning_rate": 0.0004765037593984962,
      "loss": 0.5061,
      "step": 5475
    },
    {
      "epoch": 41.35,
      "learning_rate": 0.0004759398496240601,
      "loss": 0.5126,
      "step": 5500
    },
    {
      "epoch": 41.54,
      "learning_rate": 0.000475375939849624,
      "loss": 0.5209,
      "step": 5525
    },
    {
      "epoch": 41.73,
      "learning_rate": 0.0004748120300751879,
      "loss": 0.5426,
      "step": 5550
    },
    {
      "epoch": 41.92,
      "learning_rate": 0.0004742481203007518,
      "loss": 0.5327,
      "step": 5575
    },
    {
      "epoch": 42.11,
      "learning_rate": 0.00047368421052631577,
      "loss": 0.4985,
      "step": 5600
    },
    {
      "epoch": 42.29,
      "learning_rate": 0.00047312030075187967,
      "loss": 0.4868,
      "step": 5625
    },
    {
      "epoch": 42.48,
      "learning_rate": 0.0004725563909774436,
      "loss": 0.4919,
      "step": 5650
    },
    {
      "epoch": 42.67,
      "learning_rate": 0.00047199248120300747,
      "loss": 0.4954,
      "step": 5675
    },
    {
      "epoch": 42.86,
      "learning_rate": 0.00047142857142857137,
      "loss": 0.5061,
      "step": 5700
    },
    {
      "epoch": 43.05,
      "learning_rate": 0.0004708646616541353,
      "loss": 0.5038,
      "step": 5725
    },
    {
      "epoch": 43.23,
      "learning_rate": 0.00047030075187969923,
      "loss": 0.4585,
      "step": 5750
    },
    {
      "epoch": 43.42,
      "learning_rate": 0.00046973684210526313,
      "loss": 0.474,
      "step": 5775
    },
    {
      "epoch": 43.61,
      "learning_rate": 0.000469172932330827,
      "loss": 0.4737,
      "step": 5800
    },
    {
      "epoch": 43.8,
      "learning_rate": 0.00046860902255639093,
      "loss": 0.4841,
      "step": 5825
    },
    {
      "epoch": 43.98,
      "learning_rate": 0.00046804511278195483,
      "loss": 0.4932,
      "step": 5850
    },
    {
      "epoch": 44.17,
      "learning_rate": 0.0004674812030075188,
      "loss": 0.4333,
      "step": 5875
    },
    {
      "epoch": 44.36,
      "learning_rate": 0.0004669172932330827,
      "loss": 0.4361,
      "step": 5900
    },
    {
      "epoch": 44.55,
      "learning_rate": 0.00046635338345864653,
      "loss": 0.4506,
      "step": 5925
    },
    {
      "epoch": 44.74,
      "learning_rate": 0.0004657894736842105,
      "loss": 0.4624,
      "step": 5950
    },
    {
      "epoch": 44.92,
      "learning_rate": 0.0004652255639097744,
      "loss": 0.4689,
      "step": 5975
    },
    {
      "epoch": 45.11,
      "learning_rate": 0.0004646616541353383,
      "loss": 0.4337,
      "step": 6000
    },
    {
      "epoch": 45.3,
      "learning_rate": 0.00046409774436090225,
      "loss": 0.4064,
      "step": 6025
    },
    {
      "epoch": 45.49,
      "learning_rate": 0.00046353383458646615,
      "loss": 0.4214,
      "step": 6050
    },
    {
      "epoch": 45.68,
      "learning_rate": 0.00046296992481203,
      "loss": 0.4296,
      "step": 6075
    },
    {
      "epoch": 45.86,
      "learning_rate": 0.00046240601503759395,
      "loss": 0.4333,
      "step": 6100
    },
    {
      "epoch": 46.05,
      "learning_rate": 0.00046184210526315785,
      "loss": 0.4236,
      "step": 6125
    },
    {
      "epoch": 46.24,
      "learning_rate": 0.0004612781954887218,
      "loss": 0.3794,
      "step": 6150
    },
    {
      "epoch": 46.43,
      "learning_rate": 0.0004607142857142857,
      "loss": 0.3936,
      "step": 6175
    },
    {
      "epoch": 46.62,
      "learning_rate": 0.00046015037593984955,
      "loss": 0.4056,
      "step": 6200
    },
    {
      "epoch": 46.8,
      "learning_rate": 0.00045958646616541345,
      "loss": 0.407,
      "step": 6225
    },
    {
      "epoch": 46.99,
      "learning_rate": 0.0004590225563909774,
      "loss": 0.4043,
      "step": 6250
    },
    {
      "epoch": 47.18,
      "learning_rate": 0.0004584586466165413,
      "loss": 0.3637,
      "step": 6275
    },
    {
      "epoch": 47.37,
      "learning_rate": 0.00045789473684210527,
      "loss": 0.3686,
      "step": 6300
    },
    {
      "epoch": 47.56,
      "learning_rate": 0.0004573308270676691,
      "loss": 0.3684,
      "step": 6325
    },
    {
      "epoch": 47.74,
      "learning_rate": 0.000456766917293233,
      "loss": 0.3793,
      "step": 6350
    },
    {
      "epoch": 47.93,
      "learning_rate": 0.00045620300751879697,
      "loss": 0.3914,
      "step": 6375
    },
    {
      "epoch": 48.12,
      "learning_rate": 0.00045563909774436087,
      "loss": 0.3596,
      "step": 6400
    },
    {
      "epoch": 48.31,
      "learning_rate": 0.00045507518796992477,
      "loss": 0.3403,
      "step": 6425
    },
    {
      "epoch": 48.5,
      "learning_rate": 0.0004545112781954887,
      "loss": 0.3514,
      "step": 6450
    },
    {
      "epoch": 48.68,
      "learning_rate": 0.00045394736842105257,
      "loss": 0.3596,
      "step": 6475
    },
    {
      "epoch": 48.87,
      "learning_rate": 0.0004533834586466165,
      "loss": 0.3654,
      "step": 6500
    },
    {
      "epoch": 49.06,
      "learning_rate": 0.00045281954887218043,
      "loss": 0.3514,
      "step": 6525
    },
    {
      "epoch": 49.25,
      "learning_rate": 0.00045225563909774433,
      "loss": 0.3202,
      "step": 6550
    },
    {
      "epoch": 49.44,
      "learning_rate": 0.0004516917293233083,
      "loss": 0.332,
      "step": 6575
    },
    {
      "epoch": 49.62,
      "learning_rate": 0.00045112781954887213,
      "loss": 0.3497,
      "step": 6600
    },
    {
      "epoch": 49.81,
      "learning_rate": 0.00045056390977443603,
      "loss": 0.3357,
      "step": 6625
    },
    {
      "epoch": 50.0,
      "learning_rate": 0.00045,
      "loss": 0.3522,
      "step": 6650
    },
    {
      "epoch": 50.19,
      "learning_rate": 0.0004494360902255639,
      "loss": 0.3004,
      "step": 6675
    },
    {
      "epoch": 50.38,
      "learning_rate": 0.0004488721804511278,
      "loss": 0.3044,
      "step": 6700
    },
    {
      "epoch": 50.56,
      "learning_rate": 0.00044830827067669164,
      "loss": 0.3042,
      "step": 6725
    },
    {
      "epoch": 50.75,
      "learning_rate": 0.0004477443609022556,
      "loss": 0.3084,
      "step": 6750
    },
    {
      "epoch": 50.94,
      "learning_rate": 0.0004471804511278195,
      "loss": 0.3184,
      "step": 6775
    },
    {
      "epoch": 51.13,
      "learning_rate": 0.00044661654135338345,
      "loss": 0.29,
      "step": 6800
    },
    {
      "epoch": 51.32,
      "learning_rate": 0.00044605263157894735,
      "loss": 0.2753,
      "step": 6825
    },
    {
      "epoch": 51.5,
      "learning_rate": 0.0004454887218045112,
      "loss": 0.2926,
      "step": 6850
    },
    {
      "epoch": 51.69,
      "learning_rate": 0.00044492481203007515,
      "loss": 0.2963,
      "step": 6875
    },
    {
      "epoch": 51.88,
      "learning_rate": 0.00044436090225563905,
      "loss": 0.2941,
      "step": 6900
    },
    {
      "epoch": 52.07,
      "learning_rate": 0.00044379699248120295,
      "loss": 0.2821,
      "step": 6925
    },
    {
      "epoch": 52.26,
      "learning_rate": 0.0004432330827067669,
      "loss": 0.2489,
      "step": 6950
    },
    {
      "epoch": 52.44,
      "learning_rate": 0.0004426691729323308,
      "loss": 0.2634,
      "step": 6975
    },
    {
      "epoch": 52.63,
      "learning_rate": 0.00044210526315789466,
      "loss": 0.27,
      "step": 7000
    },
    {
      "epoch": 52.82,
      "learning_rate": 0.0004415413533834586,
      "loss": 0.2732,
      "step": 7025
    },
    {
      "epoch": 53.01,
      "learning_rate": 0.0004409774436090225,
      "loss": 0.2796,
      "step": 7050
    },
    {
      "epoch": 53.2,
      "learning_rate": 0.00044041353383458647,
      "loss": 0.2296,
      "step": 7075
    },
    {
      "epoch": 53.38,
      "learning_rate": 0.00043984962406015037,
      "loss": 0.2477,
      "step": 7100
    },
    {
      "epoch": 53.57,
      "learning_rate": 0.0004392857142857142,
      "loss": 0.2467,
      "step": 7125
    },
    {
      "epoch": 53.76,
      "learning_rate": 0.0004387218045112781,
      "loss": 0.2593,
      "step": 7150
    },
    {
      "epoch": 53.95,
      "learning_rate": 0.00043815789473684207,
      "loss": 0.2635,
      "step": 7175
    },
    {
      "epoch": 54.14,
      "learning_rate": 0.00043759398496240597,
      "loss": 0.2344,
      "step": 7200
    },
    {
      "epoch": 54.32,
      "learning_rate": 0.0004370300751879699,
      "loss": 0.2245,
      "step": 7225
    },
    {
      "epoch": 54.51,
      "learning_rate": 0.0004364661654135338,
      "loss": 0.238,
      "step": 7250
    },
    {
      "epoch": 54.7,
      "learning_rate": 0.0004359022556390977,
      "loss": 0.2311,
      "step": 7275
    },
    {
      "epoch": 54.89,
      "learning_rate": 0.00043533834586466163,
      "loss": 0.2386,
      "step": 7300
    },
    {
      "epoch": 55.08,
      "learning_rate": 0.00043477443609022553,
      "loss": 0.2251,
      "step": 7325
    },
    {
      "epoch": 55.26,
      "learning_rate": 0.00043421052631578943,
      "loss": 0.2045,
      "step": 7350
    },
    {
      "epoch": 55.45,
      "learning_rate": 0.0004336466165413534,
      "loss": 0.2143,
      "step": 7375
    },
    {
      "epoch": 55.64,
      "learning_rate": 0.00043308270676691723,
      "loss": 0.212,
      "step": 7400
    },
    {
      "epoch": 55.83,
      "learning_rate": 0.00043251879699248113,
      "loss": 0.2273,
      "step": 7425
    },
    {
      "epoch": 56.02,
      "learning_rate": 0.0004319548872180451,
      "loss": 0.2171,
      "step": 7450
    },
    {
      "epoch": 56.2,
      "learning_rate": 0.000431390977443609,
      "loss": 0.1816,
      "step": 7475
    },
    {
      "epoch": 56.39,
      "learning_rate": 0.00043082706766917295,
      "loss": 0.1899,
      "step": 7500
    },
    {
      "epoch": 56.58,
      "learning_rate": 0.0004302631578947368,
      "loss": 0.1906,
      "step": 7525
    },
    {
      "epoch": 56.77,
      "learning_rate": 0.0004296992481203007,
      "loss": 0.2026,
      "step": 7550
    },
    {
      "epoch": 56.95,
      "learning_rate": 0.0004291353383458646,
      "loss": 0.2068,
      "step": 7575
    },
    {
      "epoch": 57.14,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.1824,
      "step": 7600
    },
    {
      "epoch": 57.33,
      "learning_rate": 0.00042800751879699245,
      "loss": 0.1772,
      "step": 7625
    },
    {
      "epoch": 57.52,
      "learning_rate": 0.0004274436090225563,
      "loss": 0.1772,
      "step": 7650
    },
    {
      "epoch": 57.71,
      "learning_rate": 0.00042687969924812025,
      "loss": 0.1839,
      "step": 7675
    },
    {
      "epoch": 57.89,
      "learning_rate": 0.00042631578947368415,
      "loss": 0.1931,
      "step": 7700
    },
    {
      "epoch": 58.08,
      "learning_rate": 0.0004257518796992481,
      "loss": 0.1786,
      "step": 7725
    },
    {
      "epoch": 58.27,
      "learning_rate": 0.000425187969924812,
      "loss": 0.1585,
      "step": 7750
    },
    {
      "epoch": 58.46,
      "learning_rate": 0.0004246240601503759,
      "loss": 0.1567,
      "step": 7775
    },
    {
      "epoch": 58.65,
      "learning_rate": 0.0004240601503759398,
      "loss": 0.1658,
      "step": 7800
    },
    {
      "epoch": 58.83,
      "learning_rate": 0.0004234962406015037,
      "loss": 0.1717,
      "step": 7825
    },
    {
      "epoch": 59.02,
      "learning_rate": 0.0004229323308270676,
      "loss": 0.1744,
      "step": 7850
    },
    {
      "epoch": 59.21,
      "learning_rate": 0.00042236842105263157,
      "loss": 0.151,
      "step": 7875
    },
    {
      "epoch": 59.4,
      "learning_rate": 0.00042180451127819547,
      "loss": 0.1512,
      "step": 7900
    },
    {
      "epoch": 59.59,
      "learning_rate": 0.0004212406015037593,
      "loss": 0.153,
      "step": 7925
    },
    {
      "epoch": 59.77,
      "learning_rate": 0.00042067669172932327,
      "loss": 0.1543,
      "step": 7950
    },
    {
      "epoch": 59.96,
      "learning_rate": 0.00042011278195488717,
      "loss": 0.1676,
      "step": 7975
    },
    {
      "epoch": 60.15,
      "learning_rate": 0.00041954887218045113,
      "loss": 0.1463,
      "step": 8000
    },
    {
      "epoch": 60.34,
      "learning_rate": 0.00041898496240601503,
      "loss": 0.1503,
      "step": 8025
    },
    {
      "epoch": 60.53,
      "learning_rate": 0.0004184210526315789,
      "loss": 0.1447,
      "step": 8050
    },
    {
      "epoch": 60.71,
      "learning_rate": 0.0004178571428571428,
      "loss": 0.1462,
      "step": 8075
    },
    {
      "epoch": 60.9,
      "learning_rate": 0.00041729323308270673,
      "loss": 0.1479,
      "step": 8100
    },
    {
      "epoch": 61.09,
      "learning_rate": 0.00041672932330827063,
      "loss": 0.153,
      "step": 8125
    },
    {
      "epoch": 61.28,
      "learning_rate": 0.0004161654135338346,
      "loss": 0.1266,
      "step": 8150
    },
    {
      "epoch": 61.47,
      "learning_rate": 0.0004156015037593985,
      "loss": 0.1331,
      "step": 8175
    },
    {
      "epoch": 61.65,
      "learning_rate": 0.00041503759398496234,
      "loss": 0.1335,
      "step": 8200
    },
    {
      "epoch": 61.84,
      "learning_rate": 0.0004144736842105263,
      "loss": 0.1408,
      "step": 8225
    },
    {
      "epoch": 62.03,
      "learning_rate": 0.0004139097744360902,
      "loss": 0.1404,
      "step": 8250
    },
    {
      "epoch": 62.22,
      "learning_rate": 0.0004133458646616541,
      "loss": 0.1208,
      "step": 8275
    },
    {
      "epoch": 62.41,
      "learning_rate": 0.00041278195488721805,
      "loss": 0.117,
      "step": 8300
    },
    {
      "epoch": 62.59,
      "learning_rate": 0.0004122180451127819,
      "loss": 0.1215,
      "step": 8325
    },
    {
      "epoch": 62.78,
      "learning_rate": 0.0004116541353383458,
      "loss": 0.1241,
      "step": 8350
    },
    {
      "epoch": 62.97,
      "learning_rate": 0.00041109022556390975,
      "loss": 0.1342,
      "step": 8375
    },
    {
      "epoch": 63.16,
      "learning_rate": 0.00041052631578947365,
      "loss": 0.114,
      "step": 8400
    },
    {
      "epoch": 63.35,
      "learning_rate": 0.0004099624060150376,
      "loss": 0.1127,
      "step": 8425
    },
    {
      "epoch": 63.53,
      "learning_rate": 0.00040939849624060145,
      "loss": 0.1135,
      "step": 8450
    },
    {
      "epoch": 63.72,
      "learning_rate": 0.00040883458646616535,
      "loss": 0.1235,
      "step": 8475
    },
    {
      "epoch": 63.91,
      "learning_rate": 0.00040827067669172925,
      "loss": 0.1212,
      "step": 8500
    },
    {
      "epoch": 64.1,
      "learning_rate": 0.0004077067669172932,
      "loss": 0.1104,
      "step": 8525
    },
    {
      "epoch": 64.29,
      "learning_rate": 0.0004071428571428571,
      "loss": 0.1082,
      "step": 8550
    },
    {
      "epoch": 64.47,
      "learning_rate": 0.00040657894736842107,
      "loss": 0.1131,
      "step": 8575
    },
    {
      "epoch": 64.66,
      "learning_rate": 0.0004060150375939849,
      "loss": 0.1029,
      "step": 8600
    },
    {
      "epoch": 64.85,
      "learning_rate": 0.0004054511278195488,
      "loss": 0.1135,
      "step": 8625
    },
    {
      "epoch": 65.04,
      "learning_rate": 0.00040488721804511277,
      "loss": 0.1072,
      "step": 8650
    },
    {
      "epoch": 65.23,
      "learning_rate": 0.00040432330827067667,
      "loss": 0.0957,
      "step": 8675
    },
    {
      "epoch": 65.41,
      "learning_rate": 0.00040375939849624057,
      "loss": 0.1023,
      "step": 8700
    },
    {
      "epoch": 65.6,
      "learning_rate": 0.00040319548872180447,
      "loss": 0.1061,
      "step": 8725
    },
    {
      "epoch": 65.79,
      "learning_rate": 0.0004026315789473684,
      "loss": 0.1082,
      "step": 8750
    },
    {
      "epoch": 65.98,
      "learning_rate": 0.0004020676691729323,
      "loss": 0.11,
      "step": 8775
    },
    {
      "epoch": 66.17,
      "learning_rate": 0.00040150375939849623,
      "loss": 0.0922,
      "step": 8800
    },
    {
      "epoch": 66.35,
      "learning_rate": 0.00040093984962406013,
      "loss": 0.0973,
      "step": 8825
    },
    {
      "epoch": 66.54,
      "learning_rate": 0.000400375939849624,
      "loss": 0.1005,
      "step": 8850
    },
    {
      "epoch": 66.73,
      "learning_rate": 0.00039981203007518793,
      "loss": 0.0993,
      "step": 8875
    },
    {
      "epoch": 66.92,
      "learning_rate": 0.00039924812030075183,
      "loss": 0.1017,
      "step": 8900
    },
    {
      "epoch": 67.11,
      "learning_rate": 0.0003986842105263158,
      "loss": 0.0909,
      "step": 8925
    },
    {
      "epoch": 67.29,
      "learning_rate": 0.0003981203007518797,
      "loss": 0.0921,
      "step": 8950
    },
    {
      "epoch": 67.48,
      "learning_rate": 0.0003975563909774436,
      "loss": 0.093,
      "step": 8975
    },
    {
      "epoch": 67.67,
      "learning_rate": 0.00039699248120300744,
      "loss": 0.0926,
      "step": 9000
    },
    {
      "epoch": 67.86,
      "learning_rate": 0.0003964285714285714,
      "loss": 0.094,
      "step": 9025
    },
    {
      "epoch": 68.05,
      "learning_rate": 0.0003958646616541353,
      "loss": 0.1002,
      "step": 9050
    },
    {
      "epoch": 68.23,
      "learning_rate": 0.00039530075187969925,
      "loss": 0.0868,
      "step": 9075
    },
    {
      "epoch": 68.42,
      "learning_rate": 0.00039473684210526315,
      "loss": 0.0875,
      "step": 9100
    },
    {
      "epoch": 68.61,
      "learning_rate": 0.000394172932330827,
      "loss": 0.0875,
      "step": 9125
    },
    {
      "epoch": 68.8,
      "learning_rate": 0.00039360902255639095,
      "loss": 0.0905,
      "step": 9150
    },
    {
      "epoch": 68.98,
      "learning_rate": 0.00039304511278195485,
      "loss": 0.1011,
      "step": 9175
    },
    {
      "epoch": 69.17,
      "learning_rate": 0.00039248120300751875,
      "loss": 0.0838,
      "step": 9200
    },
    {
      "epoch": 69.36,
      "learning_rate": 0.0003919172932330827,
      "loss": 0.0849,
      "step": 9225
    },
    {
      "epoch": 69.55,
      "learning_rate": 0.00039135338345864655,
      "loss": 0.0892,
      "step": 9250
    },
    {
      "epoch": 69.74,
      "learning_rate": 0.00039078947368421046,
      "loss": 0.0889,
      "step": 9275
    },
    {
      "epoch": 69.92,
      "learning_rate": 0.0003902255639097744,
      "loss": 0.0931,
      "step": 9300
    },
    {
      "epoch": 70.11,
      "learning_rate": 0.0003896616541353383,
      "loss": 0.0807,
      "step": 9325
    },
    {
      "epoch": 70.3,
      "learning_rate": 0.00038909774436090227,
      "loss": 0.0775,
      "step": 9350
    },
    {
      "epoch": 70.49,
      "learning_rate": 0.00038853383458646617,
      "loss": 0.0855,
      "step": 9375
    },
    {
      "epoch": 70.68,
      "learning_rate": 0.00038796992481203,
      "loss": 0.0866,
      "step": 9400
    },
    {
      "epoch": 70.86,
      "learning_rate": 0.0003874060150375939,
      "loss": 0.0861,
      "step": 9425
    },
    {
      "epoch": 71.05,
      "learning_rate": 0.00038684210526315787,
      "loss": 0.0797,
      "step": 9450
    },
    {
      "epoch": 71.24,
      "learning_rate": 0.00038627819548872177,
      "loss": 0.0762,
      "step": 9475
    },
    {
      "epoch": 71.43,
      "learning_rate": 0.0003857142857142857,
      "loss": 0.0767,
      "step": 9500
    },
    {
      "epoch": 71.62,
      "learning_rate": 0.0003851503759398496,
      "loss": 0.0796,
      "step": 9525
    },
    {
      "epoch": 71.8,
      "learning_rate": 0.0003845864661654135,
      "loss": 0.0829,
      "step": 9550
    },
    {
      "epoch": 71.99,
      "learning_rate": 0.00038402255639097743,
      "loss": 0.0831,
      "step": 9575
    },
    {
      "epoch": 72.18,
      "learning_rate": 0.00038345864661654133,
      "loss": 0.0792,
      "step": 9600
    },
    {
      "epoch": 72.37,
      "learning_rate": 0.00038289473684210523,
      "loss": 0.0775,
      "step": 9625
    },
    {
      "epoch": 72.56,
      "learning_rate": 0.00038233082706766913,
      "loss": 0.0797,
      "step": 9650
    },
    {
      "epoch": 72.74,
      "learning_rate": 0.00038176691729323303,
      "loss": 0.0844,
      "step": 9675
    },
    {
      "epoch": 72.93,
      "learning_rate": 0.00038120300751879693,
      "loss": 0.0867,
      "step": 9700
    },
    {
      "epoch": 73.12,
      "learning_rate": 0.0003806390977443609,
      "loss": 0.0722,
      "step": 9725
    },
    {
      "epoch": 73.31,
      "learning_rate": 0.0003800751879699248,
      "loss": 0.0752,
      "step": 9750
    },
    {
      "epoch": 73.5,
      "learning_rate": 0.00037951127819548875,
      "loss": 0.0713,
      "step": 9775
    },
    {
      "epoch": 73.68,
      "learning_rate": 0.0003789473684210526,
      "loss": 0.0732,
      "step": 9800
    },
    {
      "epoch": 73.87,
      "learning_rate": 0.0003783834586466165,
      "loss": 0.078,
      "step": 9825
    },
    {
      "epoch": 74.06,
      "learning_rate": 0.00037781954887218045,
      "loss": 0.0705,
      "step": 9850
    },
    {
      "epoch": 74.25,
      "learning_rate": 0.00037725563909774435,
      "loss": 0.0648,
      "step": 9875
    },
    {
      "epoch": 74.44,
      "learning_rate": 0.00037669172932330825,
      "loss": 0.0697,
      "step": 9900
    },
    {
      "epoch": 74.62,
      "learning_rate": 0.0003761278195488721,
      "loss": 0.0692,
      "step": 9925
    },
    {
      "epoch": 74.81,
      "learning_rate": 0.00037556390977443605,
      "loss": 0.0731,
      "step": 9950
    },
    {
      "epoch": 75.0,
      "learning_rate": 0.00037499999999999995,
      "loss": 0.0808,
      "step": 9975
    },
    {
      "epoch": 75.19,
      "learning_rate": 0.0003744360902255639,
      "loss": 0.0651,
      "step": 10000
    },
    {
      "epoch": 75.38,
      "learning_rate": 0.0003738721804511278,
      "loss": 0.0665,
      "step": 10025
    },
    {
      "epoch": 75.56,
      "learning_rate": 0.00037330827067669166,
      "loss": 0.0678,
      "step": 10050
    },
    {
      "epoch": 75.75,
      "learning_rate": 0.0003727443609022556,
      "loss": 0.0715,
      "step": 10075
    },
    {
      "epoch": 75.94,
      "learning_rate": 0.0003721804511278195,
      "loss": 0.0659,
      "step": 10100
    },
    {
      "epoch": 76.13,
      "learning_rate": 0.0003716165413533834,
      "loss": 0.0666,
      "step": 10125
    },
    {
      "epoch": 76.32,
      "learning_rate": 0.00037105263157894737,
      "loss": 0.0629,
      "step": 10150
    },
    {
      "epoch": 76.5,
      "learning_rate": 0.0003704887218045112,
      "loss": 0.0645,
      "step": 10175
    },
    {
      "epoch": 76.69,
      "learning_rate": 0.0003699248120300751,
      "loss": 0.0652,
      "step": 10200
    },
    {
      "epoch": 76.88,
      "learning_rate": 0.00036936090225563907,
      "loss": 0.0685,
      "step": 10225
    },
    {
      "epoch": 77.07,
      "learning_rate": 0.00036879699248120297,
      "loss": 0.0686,
      "step": 10250
    },
    {
      "epoch": 77.26,
      "learning_rate": 0.00036823308270676693,
      "loss": 0.0631,
      "step": 10275
    },
    {
      "epoch": 77.44,
      "learning_rate": 0.00036766917293233083,
      "loss": 0.0644,
      "step": 10300
    },
    {
      "epoch": 77.63,
      "learning_rate": 0.0003671052631578947,
      "loss": 0.0687,
      "step": 10325
    },
    {
      "epoch": 77.82,
      "learning_rate": 0.0003665413533834586,
      "loss": 0.0672,
      "step": 10350
    },
    {
      "epoch": 78.01,
      "learning_rate": 0.00036597744360902253,
      "loss": 0.066,
      "step": 10375
    },
    {
      "epoch": 78.2,
      "learning_rate": 0.00036541353383458643,
      "loss": 0.0606,
      "step": 10400
    },
    {
      "epoch": 78.38,
      "learning_rate": 0.0003648496240601504,
      "loss": 0.0629,
      "step": 10425
    },
    {
      "epoch": 78.57,
      "learning_rate": 0.00036428571428571423,
      "loss": 0.0599,
      "step": 10450
    },
    {
      "epoch": 78.76,
      "learning_rate": 0.00036372180451127814,
      "loss": 0.0656,
      "step": 10475
    },
    {
      "epoch": 78.95,
      "learning_rate": 0.0003631578947368421,
      "loss": 0.0663,
      "step": 10500
    },
    {
      "epoch": 79.14,
      "learning_rate": 0.000362593984962406,
      "loss": 0.0598,
      "step": 10525
    },
    {
      "epoch": 79.32,
      "learning_rate": 0.0003620300751879699,
      "loss": 0.0608,
      "step": 10550
    },
    {
      "epoch": 79.51,
      "learning_rate": 0.0003614661654135338,
      "loss": 0.068,
      "step": 10575
    },
    {
      "epoch": 79.7,
      "learning_rate": 0.0003609022556390977,
      "loss": 0.0673,
      "step": 10600
    },
    {
      "epoch": 79.89,
      "learning_rate": 0.0003603383458646616,
      "loss": 0.0662,
      "step": 10625
    },
    {
      "epoch": 80.08,
      "learning_rate": 0.00035977443609022555,
      "loss": 0.0581,
      "step": 10650
    },
    {
      "epoch": 80.26,
      "learning_rate": 0.00035921052631578945,
      "loss": 0.0591,
      "step": 10675
    },
    {
      "epoch": 80.45,
      "learning_rate": 0.0003586466165413534,
      "loss": 0.0564,
      "step": 10700
    },
    {
      "epoch": 80.64,
      "learning_rate": 0.00035808270676691725,
      "loss": 0.0619,
      "step": 10725
    },
    {
      "epoch": 80.83,
      "learning_rate": 0.00035751879699248115,
      "loss": 0.0637,
      "step": 10750
    },
    {
      "epoch": 81.02,
      "learning_rate": 0.0003569548872180451,
      "loss": 0.0664,
      "step": 10775
    },
    {
      "epoch": 81.2,
      "learning_rate": 0.000356390977443609,
      "loss": 0.0575,
      "step": 10800
    },
    {
      "epoch": 81.39,
      "learning_rate": 0.0003558270676691729,
      "loss": 0.0587,
      "step": 10825
    },
    {
      "epoch": 81.58,
      "learning_rate": 0.00035526315789473676,
      "loss": 0.0594,
      "step": 10850
    },
    {
      "epoch": 81.77,
      "learning_rate": 0.0003546992481203007,
      "loss": 0.0597,
      "step": 10875
    },
    {
      "epoch": 81.95,
      "learning_rate": 0.0003541353383458646,
      "loss": 0.0642,
      "step": 10900
    },
    {
      "epoch": 82.14,
      "learning_rate": 0.00035357142857142857,
      "loss": 0.0566,
      "step": 10925
    },
    {
      "epoch": 82.33,
      "learning_rate": 0.00035300751879699247,
      "loss": 0.052,
      "step": 10950
    },
    {
      "epoch": 82.52,
      "learning_rate": 0.0003524436090225563,
      "loss": 0.0577,
      "step": 10975
    },
    {
      "epoch": 82.71,
      "learning_rate": 0.00035187969924812027,
      "loss": 0.0578,
      "step": 11000
    },
    {
      "epoch": 82.89,
      "learning_rate": 0.0003513157894736842,
      "loss": 0.0635,
      "step": 11025
    },
    {
      "epoch": 83.08,
      "learning_rate": 0.0003507518796992481,
      "loss": 0.0568,
      "step": 11050
    },
    {
      "epoch": 83.27,
      "learning_rate": 0.00035018796992481203,
      "loss": 0.0566,
      "step": 11075
    },
    {
      "epoch": 83.46,
      "learning_rate": 0.00034962406015037593,
      "loss": 0.0545,
      "step": 11100
    },
    {
      "epoch": 83.65,
      "learning_rate": 0.0003490601503759398,
      "loss": 0.0581,
      "step": 11125
    },
    {
      "epoch": 83.83,
      "learning_rate": 0.00034849624060150373,
      "loss": 0.0594,
      "step": 11150
    },
    {
      "epoch": 84.02,
      "learning_rate": 0.00034793233082706763,
      "loss": 0.0523,
      "step": 11175
    },
    {
      "epoch": 84.21,
      "learning_rate": 0.0003473684210526316,
      "loss": 0.0518,
      "step": 11200
    },
    {
      "epoch": 84.4,
      "learning_rate": 0.0003468045112781955,
      "loss": 0.0505,
      "step": 11225
    },
    {
      "epoch": 84.59,
      "learning_rate": 0.00034624060150375934,
      "loss": 0.0547,
      "step": 11250
    },
    {
      "epoch": 84.77,
      "learning_rate": 0.00034567669172932324,
      "loss": 0.0563,
      "step": 11275
    },
    {
      "epoch": 84.96,
      "learning_rate": 0.0003451127819548872,
      "loss": 0.0585,
      "step": 11300
    },
    {
      "epoch": 85.15,
      "learning_rate": 0.0003445488721804511,
      "loss": 0.0495,
      "step": 11325
    },
    {
      "epoch": 85.34,
      "learning_rate": 0.00034398496240601505,
      "loss": 0.0519,
      "step": 11350
    },
    {
      "epoch": 85.53,
      "learning_rate": 0.0003434210526315789,
      "loss": 0.0543,
      "step": 11375
    },
    {
      "epoch": 85.71,
      "learning_rate": 0.0003428571428571428,
      "loss": 0.0559,
      "step": 11400
    },
    {
      "epoch": 85.9,
      "learning_rate": 0.00034229323308270675,
      "loss": 0.0572,
      "step": 11425
    },
    {
      "epoch": 86.09,
      "learning_rate": 0.00034172932330827065,
      "loss": 0.0497,
      "step": 11450
    },
    {
      "epoch": 86.28,
      "learning_rate": 0.00034116541353383455,
      "loss": 0.0516,
      "step": 11475
    },
    {
      "epoch": 86.47,
      "learning_rate": 0.0003406015037593985,
      "loss": 0.0508,
      "step": 11500
    },
    {
      "epoch": 86.65,
      "learning_rate": 0.00034003759398496236,
      "loss": 0.0566,
      "step": 11525
    },
    {
      "epoch": 86.84,
      "learning_rate": 0.00033947368421052626,
      "loss": 0.0549,
      "step": 11550
    },
    {
      "epoch": 87.03,
      "learning_rate": 0.0003389097744360902,
      "loss": 0.0557,
      "step": 11575
    },
    {
      "epoch": 87.22,
      "learning_rate": 0.0003383458646616541,
      "loss": 0.0507,
      "step": 11600
    },
    {
      "epoch": 87.41,
      "learning_rate": 0.00033778195488721807,
      "loss": 0.0527,
      "step": 11625
    },
    {
      "epoch": 87.59,
      "learning_rate": 0.0003372180451127819,
      "loss": 0.0548,
      "step": 11650
    },
    {
      "epoch": 87.78,
      "learning_rate": 0.0003366541353383458,
      "loss": 0.0532,
      "step": 11675
    },
    {
      "epoch": 87.97,
      "learning_rate": 0.0003360902255639097,
      "loss": 0.059,
      "step": 11700
    },
    {
      "epoch": 88.16,
      "learning_rate": 0.00033552631578947367,
      "loss": 0.0486,
      "step": 11725
    },
    {
      "epoch": 88.35,
      "learning_rate": 0.00033496240601503757,
      "loss": 0.0502,
      "step": 11750
    },
    {
      "epoch": 88.53,
      "learning_rate": 0.0003343984962406014,
      "loss": 0.0501,
      "step": 11775
    },
    {
      "epoch": 88.72,
      "learning_rate": 0.0003338345864661654,
      "loss": 0.0565,
      "step": 11800
    },
    {
      "epoch": 88.91,
      "learning_rate": 0.0003332706766917293,
      "loss": 0.0544,
      "step": 11825
    },
    {
      "epoch": 89.1,
      "learning_rate": 0.00033270676691729323,
      "loss": 0.0477,
      "step": 11850
    },
    {
      "epoch": 89.29,
      "learning_rate": 0.00033214285714285713,
      "loss": 0.0449,
      "step": 11875
    },
    {
      "epoch": 89.47,
      "learning_rate": 0.00033157894736842103,
      "loss": 0.0483,
      "step": 11900
    },
    {
      "epoch": 89.66,
      "learning_rate": 0.00033101503759398493,
      "loss": 0.0517,
      "step": 11925
    },
    {
      "epoch": 89.85,
      "learning_rate": 0.00033045112781954883,
      "loss": 0.0517,
      "step": 11950
    },
    {
      "epoch": 90.04,
      "learning_rate": 0.00032988721804511274,
      "loss": 0.0451,
      "step": 11975
    },
    {
      "epoch": 90.23,
      "learning_rate": 0.0003293233082706767,
      "loss": 0.0444,
      "step": 12000
    },
    {
      "epoch": 90.41,
      "learning_rate": 0.0003287593984962406,
      "loss": 0.0515,
      "step": 12025
    },
    {
      "epoch": 90.6,
      "learning_rate": 0.00032819548872180444,
      "loss": 0.0488,
      "step": 12050
    },
    {
      "epoch": 90.79,
      "learning_rate": 0.0003276315789473684,
      "loss": 0.0488,
      "step": 12075
    },
    {
      "epoch": 90.98,
      "learning_rate": 0.0003270676691729323,
      "loss": 0.052,
      "step": 12100
    },
    {
      "epoch": 91.17,
      "learning_rate": 0.00032650375939849625,
      "loss": 0.0431,
      "step": 12125
    },
    {
      "epoch": 91.35,
      "learning_rate": 0.00032593984962406015,
      "loss": 0.0469,
      "step": 12150
    },
    {
      "epoch": 91.54,
      "learning_rate": 0.000325375939849624,
      "loss": 0.0509,
      "step": 12175
    },
    {
      "epoch": 91.73,
      "learning_rate": 0.0003248120300751879,
      "loss": 0.0501,
      "step": 12200
    },
    {
      "epoch": 91.92,
      "learning_rate": 0.00032424812030075185,
      "loss": 0.0534,
      "step": 12225
    },
    {
      "epoch": 92.11,
      "learning_rate": 0.00032368421052631575,
      "loss": 0.0473,
      "step": 12250
    },
    {
      "epoch": 92.29,
      "learning_rate": 0.0003231203007518797,
      "loss": 0.0433,
      "step": 12275
    },
    {
      "epoch": 92.48,
      "learning_rate": 0.0003225563909774436,
      "loss": 0.0467,
      "step": 12300
    },
    {
      "epoch": 92.67,
      "learning_rate": 0.00032199248120300746,
      "loss": 0.0443,
      "step": 12325
    },
    {
      "epoch": 92.86,
      "learning_rate": 0.0003214285714285714,
      "loss": 0.0452,
      "step": 12350
    },
    {
      "epoch": 93.05,
      "learning_rate": 0.0003208646616541353,
      "loss": 0.0481,
      "step": 12375
    },
    {
      "epoch": 93.23,
      "learning_rate": 0.0003203007518796992,
      "loss": 0.0449,
      "step": 12400
    },
    {
      "epoch": 93.42,
      "learning_rate": 0.00031973684210526317,
      "loss": 0.0479,
      "step": 12425
    },
    {
      "epoch": 93.61,
      "learning_rate": 0.000319172932330827,
      "loss": 0.0477,
      "step": 12450
    },
    {
      "epoch": 93.8,
      "learning_rate": 0.0003186090225563909,
      "loss": 0.0479,
      "step": 12475
    },
    {
      "epoch": 93.98,
      "learning_rate": 0.00031804511278195487,
      "loss": 0.0424,
      "step": 12500
    },
    {
      "epoch": 94.17,
      "learning_rate": 0.0003174812030075188,
      "loss": 0.0442,
      "step": 12525
    },
    {
      "epoch": 94.36,
      "learning_rate": 0.00031691729323308273,
      "loss": 0.042,
      "step": 12550
    },
    {
      "epoch": 94.55,
      "learning_rate": 0.0003163533834586466,
      "loss": 0.0439,
      "step": 12575
    },
    {
      "epoch": 94.74,
      "learning_rate": 0.0003157894736842105,
      "loss": 0.0445,
      "step": 12600
    },
    {
      "epoch": 94.92,
      "learning_rate": 0.0003152255639097744,
      "loss": 0.0495,
      "step": 12625
    },
    {
      "epoch": 95.11,
      "learning_rate": 0.00031466165413533833,
      "loss": 0.0473,
      "step": 12650
    },
    {
      "epoch": 95.3,
      "learning_rate": 0.00031409774436090223,
      "loss": 0.0445,
      "step": 12675
    },
    {
      "epoch": 95.49,
      "learning_rate": 0.0003135338345864662,
      "loss": 0.0443,
      "step": 12700
    },
    {
      "epoch": 95.68,
      "learning_rate": 0.00031296992481203003,
      "loss": 0.0427,
      "step": 12725
    },
    {
      "epoch": 95.86,
      "learning_rate": 0.00031240601503759394,
      "loss": 0.0457,
      "step": 12750
    },
    {
      "epoch": 96.05,
      "learning_rate": 0.0003118421052631579,
      "loss": 0.0474,
      "step": 12775
    },
    {
      "epoch": 96.24,
      "learning_rate": 0.0003112781954887218,
      "loss": 0.0409,
      "step": 12800
    },
    {
      "epoch": 96.43,
      "learning_rate": 0.0003107142857142857,
      "loss": 0.0469,
      "step": 12825
    },
    {
      "epoch": 96.62,
      "learning_rate": 0.0003101503759398496,
      "loss": 0.0428,
      "step": 12850
    },
    {
      "epoch": 96.8,
      "learning_rate": 0.0003095864661654135,
      "loss": 0.0447,
      "step": 12875
    },
    {
      "epoch": 96.99,
      "learning_rate": 0.0003090225563909774,
      "loss": 0.0471,
      "step": 12900
    },
    {
      "epoch": 97.18,
      "learning_rate": 0.00030845864661654135,
      "loss": 0.0409,
      "step": 12925
    },
    {
      "epoch": 97.37,
      "learning_rate": 0.00030789473684210525,
      "loss": 0.0444,
      "step": 12950
    },
    {
      "epoch": 97.56,
      "learning_rate": 0.0003073308270676691,
      "loss": 0.0412,
      "step": 12975
    },
    {
      "epoch": 97.74,
      "learning_rate": 0.00030676691729323305,
      "loss": 0.0439,
      "step": 13000
    },
    {
      "epoch": 97.93,
      "learning_rate": 0.00030620300751879695,
      "loss": 0.0401,
      "step": 13025
    },
    {
      "epoch": 98.12,
      "learning_rate": 0.0003056390977443609,
      "loss": 0.0395,
      "step": 13050
    },
    {
      "epoch": 98.31,
      "learning_rate": 0.0003050751879699248,
      "loss": 0.0404,
      "step": 13075
    },
    {
      "epoch": 98.5,
      "learning_rate": 0.0003045112781954887,
      "loss": 0.0434,
      "step": 13100
    },
    {
      "epoch": 98.68,
      "learning_rate": 0.00030394736842105256,
      "loss": 0.0384,
      "step": 13125
    },
    {
      "epoch": 98.87,
      "learning_rate": 0.0003033834586466165,
      "loss": 0.0432,
      "step": 13150
    },
    {
      "epoch": 99.06,
      "learning_rate": 0.0003028195488721804,
      "loss": 0.0428,
      "step": 13175
    },
    {
      "epoch": 99.25,
      "learning_rate": 0.00030225563909774437,
      "loss": 0.0429,
      "step": 13200
    },
    {
      "epoch": 99.44,
      "learning_rate": 0.00030169172932330827,
      "loss": 0.0395,
      "step": 13225
    },
    {
      "epoch": 99.62,
      "learning_rate": 0.0003011278195488721,
      "loss": 0.0421,
      "step": 13250
    },
    {
      "epoch": 99.81,
      "learning_rate": 0.00030056390977443607,
      "loss": 0.0464,
      "step": 13275
    },
    {
      "epoch": 100.0,
      "learning_rate": 0.0003,
      "loss": 0.0423,
      "step": 13300
    },
    {
      "epoch": 100.19,
      "learning_rate": 0.0002994360902255639,
      "loss": 0.037,
      "step": 13325
    },
    {
      "epoch": 100.38,
      "learning_rate": 0.0002988721804511278,
      "loss": 0.0382,
      "step": 13350
    },
    {
      "epoch": 100.56,
      "learning_rate": 0.00029830827067669173,
      "loss": 0.0437,
      "step": 13375
    },
    {
      "epoch": 100.75,
      "learning_rate": 0.0002977443609022556,
      "loss": 0.0394,
      "step": 13400
    },
    {
      "epoch": 100.94,
      "learning_rate": 0.00029718045112781953,
      "loss": 0.0404,
      "step": 13425
    },
    {
      "epoch": 101.13,
      "learning_rate": 0.00029661654135338343,
      "loss": 0.0407,
      "step": 13450
    },
    {
      "epoch": 101.32,
      "learning_rate": 0.00029605263157894733,
      "loss": 0.038,
      "step": 13475
    },
    {
      "epoch": 101.5,
      "learning_rate": 0.00029548872180451124,
      "loss": 0.0379,
      "step": 13500
    },
    {
      "epoch": 101.69,
      "learning_rate": 0.0002949248120300752,
      "loss": 0.0411,
      "step": 13525
    },
    {
      "epoch": 101.88,
      "learning_rate": 0.00029436090225563904,
      "loss": 0.045,
      "step": 13550
    },
    {
      "epoch": 102.07,
      "learning_rate": 0.000293796992481203,
      "loss": 0.0398,
      "step": 13575
    },
    {
      "epoch": 102.26,
      "learning_rate": 0.0002932330827067669,
      "loss": 0.0377,
      "step": 13600
    },
    {
      "epoch": 102.44,
      "learning_rate": 0.0002926691729323308,
      "loss": 0.0368,
      "step": 13625
    },
    {
      "epoch": 102.63,
      "learning_rate": 0.0002921052631578947,
      "loss": 0.0385,
      "step": 13650
    },
    {
      "epoch": 102.82,
      "learning_rate": 0.0002915413533834586,
      "loss": 0.0442,
      "step": 13675
    },
    {
      "epoch": 103.01,
      "learning_rate": 0.00029097744360902255,
      "loss": 0.0421,
      "step": 13700
    },
    {
      "epoch": 103.2,
      "learning_rate": 0.00029041353383458645,
      "loss": 0.0371,
      "step": 13725
    },
    {
      "epoch": 103.38,
      "learning_rate": 0.00028984962406015035,
      "loss": 0.0375,
      "step": 13750
    },
    {
      "epoch": 103.57,
      "learning_rate": 0.00028928571428571425,
      "loss": 0.0381,
      "step": 13775
    },
    {
      "epoch": 103.76,
      "learning_rate": 0.00028872180451127816,
      "loss": 0.0401,
      "step": 13800
    },
    {
      "epoch": 103.95,
      "learning_rate": 0.00028815789473684206,
      "loss": 0.0439,
      "step": 13825
    },
    {
      "epoch": 104.14,
      "learning_rate": 0.000287593984962406,
      "loss": 0.0379,
      "step": 13850
    },
    {
      "epoch": 104.32,
      "learning_rate": 0.0002870300751879699,
      "loss": 0.0385,
      "step": 13875
    },
    {
      "epoch": 104.51,
      "learning_rate": 0.0002864661654135338,
      "loss": 0.0333,
      "step": 13900
    },
    {
      "epoch": 104.7,
      "learning_rate": 0.0002859022556390977,
      "loss": 0.0377,
      "step": 13925
    },
    {
      "epoch": 104.89,
      "learning_rate": 0.0002853383458646616,
      "loss": 0.0393,
      "step": 13950
    },
    {
      "epoch": 105.08,
      "learning_rate": 0.00028477443609022557,
      "loss": 0.0413,
      "step": 13975
    },
    {
      "epoch": 105.26,
      "learning_rate": 0.0002842105263157894,
      "loss": 0.0383,
      "step": 14000
    },
    {
      "epoch": 105.45,
      "learning_rate": 0.00028364661654135337,
      "loss": 0.0363,
      "step": 14025
    },
    {
      "epoch": 105.64,
      "learning_rate": 0.0002830827067669173,
      "loss": 0.038,
      "step": 14050
    },
    {
      "epoch": 105.83,
      "learning_rate": 0.0002825187969924812,
      "loss": 0.0358,
      "step": 14075
    },
    {
      "epoch": 106.02,
      "learning_rate": 0.0002819548872180451,
      "loss": 0.0378,
      "step": 14100
    },
    {
      "epoch": 106.2,
      "learning_rate": 0.00028139097744360903,
      "loss": 0.0325,
      "step": 14125
    },
    {
      "epoch": 106.39,
      "learning_rate": 0.0002808270676691729,
      "loss": 0.035,
      "step": 14150
    },
    {
      "epoch": 106.58,
      "learning_rate": 0.00028026315789473683,
      "loss": 0.036,
      "step": 14175
    },
    {
      "epoch": 106.77,
      "learning_rate": 0.00027969924812030073,
      "loss": 0.0357,
      "step": 14200
    },
    {
      "epoch": 106.95,
      "learning_rate": 0.00027913533834586463,
      "loss": 0.038,
      "step": 14225
    },
    {
      "epoch": 107.14,
      "learning_rate": 0.00027857142857142854,
      "loss": 0.0328,
      "step": 14250
    },
    {
      "epoch": 107.33,
      "learning_rate": 0.00027800751879699244,
      "loss": 0.0343,
      "step": 14275
    },
    {
      "epoch": 107.52,
      "learning_rate": 0.0002774436090225564,
      "loss": 0.0383,
      "step": 14300
    },
    {
      "epoch": 107.71,
      "learning_rate": 0.0002768796992481203,
      "loss": 0.0368,
      "step": 14325
    },
    {
      "epoch": 107.89,
      "learning_rate": 0.0002763157894736842,
      "loss": 0.0353,
      "step": 14350
    },
    {
      "epoch": 108.08,
      "learning_rate": 0.0002757518796992481,
      "loss": 0.0373,
      "step": 14375
    },
    {
      "epoch": 108.27,
      "learning_rate": 0.000275187969924812,
      "loss": 0.0322,
      "step": 14400
    },
    {
      "epoch": 108.46,
      "learning_rate": 0.0002746240601503759,
      "loss": 0.033,
      "step": 14425
    },
    {
      "epoch": 108.65,
      "learning_rate": 0.00027406015037593985,
      "loss": 0.0347,
      "step": 14450
    },
    {
      "epoch": 108.83,
      "learning_rate": 0.0002734962406015037,
      "loss": 0.0352,
      "step": 14475
    },
    {
      "epoch": 109.02,
      "learning_rate": 0.00027293233082706765,
      "loss": 0.0378,
      "step": 14500
    },
    {
      "epoch": 109.21,
      "learning_rate": 0.00027236842105263155,
      "loss": 0.0301,
      "step": 14525
    },
    {
      "epoch": 109.4,
      "learning_rate": 0.00027180451127819546,
      "loss": 0.0362,
      "step": 14550
    },
    {
      "epoch": 109.59,
      "learning_rate": 0.00027124060150375936,
      "loss": 0.0325,
      "step": 14575
    },
    {
      "epoch": 109.77,
      "learning_rate": 0.00027067669172932326,
      "loss": 0.0371,
      "step": 14600
    },
    {
      "epoch": 109.96,
      "learning_rate": 0.0002701127819548872,
      "loss": 0.0367,
      "step": 14625
    },
    {
      "epoch": 110.15,
      "learning_rate": 0.0002695488721804511,
      "loss": 0.0316,
      "step": 14650
    },
    {
      "epoch": 110.34,
      "learning_rate": 0.000268984962406015,
      "loss": 0.0317,
      "step": 14675
    },
    {
      "epoch": 110.53,
      "learning_rate": 0.0002684210526315789,
      "loss": 0.0294,
      "step": 14700
    },
    {
      "epoch": 110.71,
      "learning_rate": 0.00026785714285714287,
      "loss": 0.0326,
      "step": 14725
    },
    {
      "epoch": 110.9,
      "learning_rate": 0.0002672932330827067,
      "loss": 0.036,
      "step": 14750
    },
    {
      "epoch": 111.09,
      "learning_rate": 0.00026672932330827067,
      "loss": 0.0313,
      "step": 14775
    },
    {
      "epoch": 111.28,
      "learning_rate": 0.0002661654135338346,
      "loss": 0.0348,
      "step": 14800
    },
    {
      "epoch": 111.47,
      "learning_rate": 0.0002656015037593985,
      "loss": 0.0343,
      "step": 14825
    },
    {
      "epoch": 111.65,
      "learning_rate": 0.0002650375939849624,
      "loss": 0.0337,
      "step": 14850
    },
    {
      "epoch": 111.84,
      "learning_rate": 0.0002644736842105263,
      "loss": 0.0361,
      "step": 14875
    },
    {
      "epoch": 112.03,
      "learning_rate": 0.00026390977443609023,
      "loss": 0.0356,
      "step": 14900
    },
    {
      "epoch": 112.22,
      "learning_rate": 0.00026334586466165413,
      "loss": 0.0333,
      "step": 14925
    },
    {
      "epoch": 112.41,
      "learning_rate": 0.00026278195488721803,
      "loss": 0.0355,
      "step": 14950
    },
    {
      "epoch": 112.59,
      "learning_rate": 0.00026221804511278193,
      "loss": 0.0313,
      "step": 14975
    },
    {
      "epoch": 112.78,
      "learning_rate": 0.00026165413533834584,
      "loss": 0.0322,
      "step": 15000
    },
    {
      "epoch": 112.97,
      "learning_rate": 0.00026109022556390974,
      "loss": 0.0343,
      "step": 15025
    },
    {
      "epoch": 113.16,
      "learning_rate": 0.0002605263157894737,
      "loss": 0.0299,
      "step": 15050
    },
    {
      "epoch": 113.35,
      "learning_rate": 0.00025996240601503754,
      "loss": 0.0288,
      "step": 15075
    },
    {
      "epoch": 113.53,
      "learning_rate": 0.0002593984962406015,
      "loss": 0.0289,
      "step": 15100
    },
    {
      "epoch": 113.72,
      "learning_rate": 0.0002588345864661654,
      "loss": 0.0347,
      "step": 15125
    },
    {
      "epoch": 113.91,
      "learning_rate": 0.0002582706766917293,
      "loss": 0.0386,
      "step": 15150
    },
    {
      "epoch": 114.1,
      "learning_rate": 0.0002577067669172932,
      "loss": 0.0321,
      "step": 15175
    },
    {
      "epoch": 114.29,
      "learning_rate": 0.0002571428571428571,
      "loss": 0.0307,
      "step": 15200
    },
    {
      "epoch": 114.47,
      "learning_rate": 0.00025657894736842105,
      "loss": 0.0333,
      "step": 15225
    },
    {
      "epoch": 114.66,
      "learning_rate": 0.00025601503759398495,
      "loss": 0.0352,
      "step": 15250
    },
    {
      "epoch": 114.85,
      "learning_rate": 0.00025545112781954885,
      "loss": 0.0322,
      "step": 15275
    },
    {
      "epoch": 115.04,
      "learning_rate": 0.00025488721804511276,
      "loss": 0.0289,
      "step": 15300
    },
    {
      "epoch": 115.23,
      "learning_rate": 0.0002543233082706767,
      "loss": 0.0292,
      "step": 15325
    },
    {
      "epoch": 115.41,
      "learning_rate": 0.00025375939849624056,
      "loss": 0.0338,
      "step": 15350
    },
    {
      "epoch": 115.6,
      "learning_rate": 0.0002531954887218045,
      "loss": 0.0311,
      "step": 15375
    },
    {
      "epoch": 115.79,
      "learning_rate": 0.00025263157894736836,
      "loss": 0.0348,
      "step": 15400
    },
    {
      "epoch": 115.98,
      "learning_rate": 0.0002520676691729323,
      "loss": 0.0355,
      "step": 15425
    },
    {
      "epoch": 116.17,
      "learning_rate": 0.0002515037593984962,
      "loss": 0.0289,
      "step": 15450
    },
    {
      "epoch": 116.35,
      "learning_rate": 0.0002509398496240601,
      "loss": 0.0303,
      "step": 15475
    },
    {
      "epoch": 116.54,
      "learning_rate": 0.000250375939849624,
      "loss": 0.0327,
      "step": 15500
    },
    {
      "epoch": 116.73,
      "learning_rate": 0.00024981203007518797,
      "loss": 0.0323,
      "step": 15525
    },
    {
      "epoch": 116.92,
      "learning_rate": 0.0002492481203007519,
      "loss": 0.03,
      "step": 15550
    },
    {
      "epoch": 117.11,
      "learning_rate": 0.0002486842105263158,
      "loss": 0.0293,
      "step": 15575
    },
    {
      "epoch": 117.29,
      "learning_rate": 0.0002481203007518797,
      "loss": 0.0286,
      "step": 15600
    },
    {
      "epoch": 117.48,
      "learning_rate": 0.0002475563909774436,
      "loss": 0.0297,
      "step": 15625
    },
    {
      "epoch": 117.67,
      "learning_rate": 0.00024699248120300753,
      "loss": 0.0326,
      "step": 15650
    },
    {
      "epoch": 117.86,
      "learning_rate": 0.0002464285714285714,
      "loss": 0.0324,
      "step": 15675
    },
    {
      "epoch": 118.05,
      "learning_rate": 0.00024586466165413533,
      "loss": 0.033,
      "step": 15700
    },
    {
      "epoch": 118.23,
      "learning_rate": 0.00024530075187969923,
      "loss": 0.0249,
      "step": 15725
    },
    {
      "epoch": 118.42,
      "learning_rate": 0.00024473684210526314,
      "loss": 0.0253,
      "step": 15750
    },
    {
      "epoch": 118.61,
      "learning_rate": 0.00024417293233082704,
      "loss": 0.0316,
      "step": 15775
    },
    {
      "epoch": 118.8,
      "learning_rate": 0.00024360902255639094,
      "loss": 0.0319,
      "step": 15800
    },
    {
      "epoch": 118.98,
      "learning_rate": 0.00024304511278195487,
      "loss": 0.0331,
      "step": 15825
    },
    {
      "epoch": 119.17,
      "learning_rate": 0.0002424812030075188,
      "loss": 0.0263,
      "step": 15850
    },
    {
      "epoch": 119.36,
      "learning_rate": 0.00024191729323308267,
      "loss": 0.0293,
      "step": 15875
    },
    {
      "epoch": 119.55,
      "learning_rate": 0.0002413533834586466,
      "loss": 0.0289,
      "step": 15900
    },
    {
      "epoch": 119.74,
      "learning_rate": 0.00024078947368421052,
      "loss": 0.0302,
      "step": 15925
    },
    {
      "epoch": 119.92,
      "learning_rate": 0.0002402255639097744,
      "loss": 0.0299,
      "step": 15950
    },
    {
      "epoch": 120.11,
      "learning_rate": 0.00023966165413533832,
      "loss": 0.0293,
      "step": 15975
    },
    {
      "epoch": 120.3,
      "learning_rate": 0.00023909774436090223,
      "loss": 0.0259,
      "step": 16000
    },
    {
      "epoch": 120.49,
      "learning_rate": 0.00023853383458646615,
      "loss": 0.0312,
      "step": 16025
    },
    {
      "epoch": 120.68,
      "learning_rate": 0.00023796992481203005,
      "loss": 0.0302,
      "step": 16050
    },
    {
      "epoch": 120.86,
      "learning_rate": 0.00023740601503759396,
      "loss": 0.0295,
      "step": 16075
    },
    {
      "epoch": 121.05,
      "learning_rate": 0.00023684210526315788,
      "loss": 0.0295,
      "step": 16100
    },
    {
      "epoch": 121.24,
      "learning_rate": 0.0002362781954887218,
      "loss": 0.0276,
      "step": 16125
    },
    {
      "epoch": 121.43,
      "learning_rate": 0.00023571428571428569,
      "loss": 0.0269,
      "step": 16150
    },
    {
      "epoch": 121.62,
      "learning_rate": 0.00023515037593984961,
      "loss": 0.0316,
      "step": 16175
    },
    {
      "epoch": 121.8,
      "learning_rate": 0.0002345864661654135,
      "loss": 0.0319,
      "step": 16200
    },
    {
      "epoch": 121.99,
      "learning_rate": 0.00023402255639097742,
      "loss": 0.0305,
      "step": 16225
    },
    {
      "epoch": 122.18,
      "learning_rate": 0.00023345864661654134,
      "loss": 0.026,
      "step": 16250
    },
    {
      "epoch": 122.37,
      "learning_rate": 0.00023289473684210524,
      "loss": 0.0273,
      "step": 16275
    },
    {
      "epoch": 122.56,
      "learning_rate": 0.00023233082706766915,
      "loss": 0.0303,
      "step": 16300
    },
    {
      "epoch": 122.74,
      "learning_rate": 0.00023176691729323307,
      "loss": 0.0292,
      "step": 16325
    },
    {
      "epoch": 122.93,
      "learning_rate": 0.00023120300751879697,
      "loss": 0.0274,
      "step": 16350
    },
    {
      "epoch": 123.12,
      "learning_rate": 0.0002306390977443609,
      "loss": 0.0302,
      "step": 16375
    },
    {
      "epoch": 123.31,
      "learning_rate": 0.00023007518796992478,
      "loss": 0.0261,
      "step": 16400
    },
    {
      "epoch": 123.5,
      "learning_rate": 0.0002295112781954887,
      "loss": 0.0296,
      "step": 16425
    },
    {
      "epoch": 123.68,
      "learning_rate": 0.00022894736842105263,
      "loss": 0.0261,
      "step": 16450
    },
    {
      "epoch": 123.87,
      "learning_rate": 0.0002283834586466165,
      "loss": 0.0298,
      "step": 16475
    },
    {
      "epoch": 124.06,
      "learning_rate": 0.00022781954887218043,
      "loss": 0.0297,
      "step": 16500
    },
    {
      "epoch": 124.25,
      "learning_rate": 0.00022725563909774436,
      "loss": 0.0268,
      "step": 16525
    },
    {
      "epoch": 124.44,
      "learning_rate": 0.00022669172932330824,
      "loss": 0.0255,
      "step": 16550
    },
    {
      "epoch": 124.62,
      "learning_rate": 0.00022612781954887216,
      "loss": 0.0291,
      "step": 16575
    },
    {
      "epoch": 124.81,
      "learning_rate": 0.00022556390977443607,
      "loss": 0.0283,
      "step": 16600
    },
    {
      "epoch": 125.0,
      "learning_rate": 0.000225,
      "loss": 0.0291,
      "step": 16625
    },
    {
      "epoch": 125.19,
      "learning_rate": 0.0002244360902255639,
      "loss": 0.0243,
      "step": 16650
    },
    {
      "epoch": 125.38,
      "learning_rate": 0.0002238721804511278,
      "loss": 0.0251,
      "step": 16675
    },
    {
      "epoch": 125.56,
      "learning_rate": 0.00022330827067669172,
      "loss": 0.0281,
      "step": 16700
    },
    {
      "epoch": 125.75,
      "learning_rate": 0.0002227443609022556,
      "loss": 0.0273,
      "step": 16725
    },
    {
      "epoch": 125.94,
      "learning_rate": 0.00022218045112781953,
      "loss": 0.0268,
      "step": 16750
    },
    {
      "epoch": 126.13,
      "learning_rate": 0.00022161654135338345,
      "loss": 0.0291,
      "step": 16775
    },
    {
      "epoch": 126.32,
      "learning_rate": 0.00022105263157894733,
      "loss": 0.0266,
      "step": 16800
    },
    {
      "epoch": 126.5,
      "learning_rate": 0.00022048872180451126,
      "loss": 0.0284,
      "step": 16825
    },
    {
      "epoch": 126.69,
      "learning_rate": 0.00021992481203007518,
      "loss": 0.0239,
      "step": 16850
    },
    {
      "epoch": 126.88,
      "learning_rate": 0.00021936090225563906,
      "loss": 0.0274,
      "step": 16875
    },
    {
      "epoch": 127.07,
      "learning_rate": 0.00021879699248120299,
      "loss": 0.0263,
      "step": 16900
    },
    {
      "epoch": 127.26,
      "learning_rate": 0.0002182330827067669,
      "loss": 0.0263,
      "step": 16925
    },
    {
      "epoch": 127.44,
      "learning_rate": 0.00021766917293233081,
      "loss": 0.0301,
      "step": 16950
    },
    {
      "epoch": 127.63,
      "learning_rate": 0.00021710526315789472,
      "loss": 0.0286,
      "step": 16975
    },
    {
      "epoch": 127.82,
      "learning_rate": 0.00021654135338345862,
      "loss": 0.026,
      "step": 17000
    },
    {
      "epoch": 128.01,
      "learning_rate": 0.00021597744360902254,
      "loss": 0.0252,
      "step": 17025
    },
    {
      "epoch": 128.2,
      "learning_rate": 0.00021541353383458647,
      "loss": 0.0248,
      "step": 17050
    },
    {
      "epoch": 128.38,
      "learning_rate": 0.00021484962406015035,
      "loss": 0.028,
      "step": 17075
    },
    {
      "epoch": 128.57,
      "learning_rate": 0.00021428571428571427,
      "loss": 0.0259,
      "step": 17100
    },
    {
      "epoch": 128.76,
      "learning_rate": 0.00021372180451127815,
      "loss": 0.0274,
      "step": 17125
    },
    {
      "epoch": 128.95,
      "learning_rate": 0.00021315789473684208,
      "loss": 0.028,
      "step": 17150
    },
    {
      "epoch": 129.14,
      "learning_rate": 0.000212593984962406,
      "loss": 0.0234,
      "step": 17175
    },
    {
      "epoch": 129.32,
      "learning_rate": 0.0002120300751879699,
      "loss": 0.0258,
      "step": 17200
    },
    {
      "epoch": 129.51,
      "learning_rate": 0.0002114661654135338,
      "loss": 0.0287,
      "step": 17225
    },
    {
      "epoch": 129.7,
      "learning_rate": 0.00021090225563909773,
      "loss": 0.0257,
      "step": 17250
    },
    {
      "epoch": 129.89,
      "learning_rate": 0.00021033834586466164,
      "loss": 0.0265,
      "step": 17275
    },
    {
      "epoch": 130.08,
      "learning_rate": 0.00020977443609022556,
      "loss": 0.0273,
      "step": 17300
    },
    {
      "epoch": 130.26,
      "learning_rate": 0.00020921052631578944,
      "loss": 0.0252,
      "step": 17325
    },
    {
      "epoch": 130.45,
      "learning_rate": 0.00020864661654135337,
      "loss": 0.0276,
      "step": 17350
    },
    {
      "epoch": 130.64,
      "learning_rate": 0.0002080827067669173,
      "loss": 0.0239,
      "step": 17375
    },
    {
      "epoch": 130.83,
      "learning_rate": 0.00020751879699248117,
      "loss": 0.0278,
      "step": 17400
    },
    {
      "epoch": 131.02,
      "learning_rate": 0.0002069548872180451,
      "loss": 0.0258,
      "step": 17425
    },
    {
      "epoch": 131.2,
      "learning_rate": 0.00020639097744360902,
      "loss": 0.022,
      "step": 17450
    },
    {
      "epoch": 131.39,
      "learning_rate": 0.0002058270676691729,
      "loss": 0.0266,
      "step": 17475
    },
    {
      "epoch": 131.58,
      "learning_rate": 0.00020526315789473683,
      "loss": 0.024,
      "step": 17500
    },
    {
      "epoch": 131.77,
      "learning_rate": 0.00020469924812030073,
      "loss": 0.0242,
      "step": 17525
    },
    {
      "epoch": 131.95,
      "learning_rate": 0.00020413533834586463,
      "loss": 0.0261,
      "step": 17550
    },
    {
      "epoch": 132.14,
      "learning_rate": 0.00020357142857142856,
      "loss": 0.0249,
      "step": 17575
    },
    {
      "epoch": 132.33,
      "learning_rate": 0.00020300751879699246,
      "loss": 0.0234,
      "step": 17600
    },
    {
      "epoch": 132.52,
      "learning_rate": 0.00020244360902255638,
      "loss": 0.0241,
      "step": 17625
    },
    {
      "epoch": 132.71,
      "learning_rate": 0.00020187969924812029,
      "loss": 0.0241,
      "step": 17650
    },
    {
      "epoch": 132.89,
      "learning_rate": 0.0002013157894736842,
      "loss": 0.0265,
      "step": 17675
    },
    {
      "epoch": 133.08,
      "learning_rate": 0.00020075187969924811,
      "loss": 0.0249,
      "step": 17700
    },
    {
      "epoch": 133.27,
      "learning_rate": 0.000200187969924812,
      "loss": 0.0215,
      "step": 17725
    },
    {
      "epoch": 133.46,
      "learning_rate": 0.00019962406015037592,
      "loss": 0.0237,
      "step": 17750
    },
    {
      "epoch": 133.65,
      "learning_rate": 0.00019906015037593984,
      "loss": 0.0245,
      "step": 17775
    },
    {
      "epoch": 133.83,
      "learning_rate": 0.00019849624060150372,
      "loss": 0.0261,
      "step": 17800
    },
    {
      "epoch": 134.02,
      "learning_rate": 0.00019793233082706765,
      "loss": 0.0249,
      "step": 17825
    },
    {
      "epoch": 134.21,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.0245,
      "step": 17850
    },
    {
      "epoch": 134.4,
      "learning_rate": 0.00019680451127819548,
      "loss": 0.0263,
      "step": 17875
    },
    {
      "epoch": 134.59,
      "learning_rate": 0.00019624060150375938,
      "loss": 0.0262,
      "step": 17900
    },
    {
      "epoch": 134.77,
      "learning_rate": 0.00019567669172932328,
      "loss": 0.0268,
      "step": 17925
    },
    {
      "epoch": 134.96,
      "learning_rate": 0.0001951127819548872,
      "loss": 0.0248,
      "step": 17950
    },
    {
      "epoch": 135.15,
      "learning_rate": 0.00019454887218045113,
      "loss": 0.0233,
      "step": 17975
    },
    {
      "epoch": 135.34,
      "learning_rate": 0.000193984962406015,
      "loss": 0.026,
      "step": 18000
    },
    {
      "epoch": 135.53,
      "learning_rate": 0.00019342105263157894,
      "loss": 0.0225,
      "step": 18025
    },
    {
      "epoch": 135.71,
      "learning_rate": 0.00019285714285714286,
      "loss": 0.0254,
      "step": 18050
    },
    {
      "epoch": 135.9,
      "learning_rate": 0.00019229323308270674,
      "loss": 0.0263,
      "step": 18075
    },
    {
      "epoch": 136.09,
      "learning_rate": 0.00019172932330827067,
      "loss": 0.0239,
      "step": 18100
    },
    {
      "epoch": 136.28,
      "learning_rate": 0.00019116541353383457,
      "loss": 0.0205,
      "step": 18125
    },
    {
      "epoch": 136.47,
      "learning_rate": 0.00019060150375939847,
      "loss": 0.0233,
      "step": 18150
    },
    {
      "epoch": 136.65,
      "learning_rate": 0.0001900375939849624,
      "loss": 0.0248,
      "step": 18175
    },
    {
      "epoch": 136.84,
      "learning_rate": 0.0001894736842105263,
      "loss": 0.0235,
      "step": 18200
    },
    {
      "epoch": 137.03,
      "learning_rate": 0.00018890977443609022,
      "loss": 0.0238,
      "step": 18225
    },
    {
      "epoch": 137.22,
      "learning_rate": 0.00018834586466165413,
      "loss": 0.02,
      "step": 18250
    },
    {
      "epoch": 137.41,
      "learning_rate": 0.00018778195488721803,
      "loss": 0.0249,
      "step": 18275
    },
    {
      "epoch": 137.59,
      "learning_rate": 0.00018721804511278195,
      "loss": 0.0237,
      "step": 18300
    },
    {
      "epoch": 137.78,
      "learning_rate": 0.00018665413533834583,
      "loss": 0.0241,
      "step": 18325
    },
    {
      "epoch": 137.97,
      "learning_rate": 0.00018609022556390976,
      "loss": 0.0276,
      "step": 18350
    },
    {
      "epoch": 138.16,
      "learning_rate": 0.00018552631578947368,
      "loss": 0.0224,
      "step": 18375
    },
    {
      "epoch": 138.35,
      "learning_rate": 0.00018496240601503756,
      "loss": 0.0222,
      "step": 18400
    },
    {
      "epoch": 138.53,
      "learning_rate": 0.00018439849624060149,
      "loss": 0.0238,
      "step": 18425
    },
    {
      "epoch": 138.72,
      "learning_rate": 0.00018383458646616541,
      "loss": 0.0223,
      "step": 18450
    },
    {
      "epoch": 138.91,
      "learning_rate": 0.0001832706766917293,
      "loss": 0.025,
      "step": 18475
    },
    {
      "epoch": 139.1,
      "learning_rate": 0.00018270676691729322,
      "loss": 0.0227,
      "step": 18500
    },
    {
      "epoch": 139.29,
      "learning_rate": 0.00018214285714285712,
      "loss": 0.0248,
      "step": 18525
    },
    {
      "epoch": 139.47,
      "learning_rate": 0.00018157894736842105,
      "loss": 0.0234,
      "step": 18550
    },
    {
      "epoch": 139.66,
      "learning_rate": 0.00018101503759398495,
      "loss": 0.022,
      "step": 18575
    },
    {
      "epoch": 139.85,
      "learning_rate": 0.00018045112781954885,
      "loss": 0.0258,
      "step": 18600
    },
    {
      "epoch": 140.04,
      "learning_rate": 0.00017988721804511278,
      "loss": 0.0251,
      "step": 18625
    },
    {
      "epoch": 140.23,
      "learning_rate": 0.0001793233082706767,
      "loss": 0.023,
      "step": 18650
    },
    {
      "epoch": 140.41,
      "learning_rate": 0.00017875939849624058,
      "loss": 0.0208,
      "step": 18675
    },
    {
      "epoch": 140.6,
      "learning_rate": 0.0001781954887218045,
      "loss": 0.0224,
      "step": 18700
    },
    {
      "epoch": 140.79,
      "learning_rate": 0.00017763157894736838,
      "loss": 0.0212,
      "step": 18725
    },
    {
      "epoch": 140.98,
      "learning_rate": 0.0001770676691729323,
      "loss": 0.0258,
      "step": 18750
    },
    {
      "epoch": 141.17,
      "learning_rate": 0.00017650375939849624,
      "loss": 0.0219,
      "step": 18775
    },
    {
      "epoch": 141.35,
      "learning_rate": 0.00017593984962406014,
      "loss": 0.0215,
      "step": 18800
    },
    {
      "epoch": 141.54,
      "learning_rate": 0.00017537593984962404,
      "loss": 0.0183,
      "step": 18825
    },
    {
      "epoch": 141.73,
      "learning_rate": 0.00017481203007518797,
      "loss": 0.0263,
      "step": 18850
    },
    {
      "epoch": 141.92,
      "learning_rate": 0.00017424812030075187,
      "loss": 0.0227,
      "step": 18875
    },
    {
      "epoch": 142.11,
      "learning_rate": 0.0001736842105263158,
      "loss": 0.0219,
      "step": 18900
    },
    {
      "epoch": 142.29,
      "learning_rate": 0.00017312030075187967,
      "loss": 0.0199,
      "step": 18925
    },
    {
      "epoch": 142.48,
      "learning_rate": 0.0001725563909774436,
      "loss": 0.022,
      "step": 18950
    },
    {
      "epoch": 142.67,
      "learning_rate": 0.00017199248120300752,
      "loss": 0.0197,
      "step": 18975
    },
    {
      "epoch": 142.86,
      "learning_rate": 0.0001714285714285714,
      "loss": 0.0236,
      "step": 19000
    },
    {
      "epoch": 143.05,
      "learning_rate": 0.00017086466165413533,
      "loss": 0.0233,
      "step": 19025
    },
    {
      "epoch": 143.23,
      "learning_rate": 0.00017030075187969925,
      "loss": 0.0221,
      "step": 19050
    },
    {
      "epoch": 143.42,
      "learning_rate": 0.00016973684210526313,
      "loss": 0.0208,
      "step": 19075
    },
    {
      "epoch": 143.61,
      "learning_rate": 0.00016917293233082706,
      "loss": 0.0221,
      "step": 19100
    },
    {
      "epoch": 143.8,
      "learning_rate": 0.00016860902255639096,
      "loss": 0.0223,
      "step": 19125
    },
    {
      "epoch": 143.98,
      "learning_rate": 0.00016804511278195486,
      "loss": 0.0213,
      "step": 19150
    },
    {
      "epoch": 144.17,
      "learning_rate": 0.00016748120300751879,
      "loss": 0.0227,
      "step": 19175
    },
    {
      "epoch": 144.36,
      "learning_rate": 0.0001669172932330827,
      "loss": 0.0191,
      "step": 19200
    },
    {
      "epoch": 144.55,
      "learning_rate": 0.00016635338345864662,
      "loss": 0.0209,
      "step": 19225
    },
    {
      "epoch": 144.74,
      "learning_rate": 0.00016578947368421052,
      "loss": 0.0212,
      "step": 19250
    },
    {
      "epoch": 144.92,
      "learning_rate": 0.00016522556390977442,
      "loss": 0.0234,
      "step": 19275
    },
    {
      "epoch": 145.11,
      "learning_rate": 0.00016466165413533835,
      "loss": 0.0212,
      "step": 19300
    },
    {
      "epoch": 145.3,
      "learning_rate": 0.00016409774436090222,
      "loss": 0.0181,
      "step": 19325
    },
    {
      "epoch": 145.49,
      "learning_rate": 0.00016353383458646615,
      "loss": 0.0207,
      "step": 19350
    },
    {
      "epoch": 145.68,
      "learning_rate": 0.00016296992481203008,
      "loss": 0.0213,
      "step": 19375
    },
    {
      "epoch": 145.86,
      "learning_rate": 0.00016240601503759395,
      "loss": 0.0212,
      "step": 19400
    },
    {
      "epoch": 146.05,
      "learning_rate": 0.00016184210526315788,
      "loss": 0.0201,
      "step": 19425
    },
    {
      "epoch": 146.24,
      "learning_rate": 0.0001612781954887218,
      "loss": 0.0192,
      "step": 19450
    },
    {
      "epoch": 146.43,
      "learning_rate": 0.0001607142857142857,
      "loss": 0.0199,
      "step": 19475
    },
    {
      "epoch": 146.62,
      "learning_rate": 0.0001601503759398496,
      "loss": 0.0219,
      "step": 19500
    },
    {
      "epoch": 146.8,
      "learning_rate": 0.0001595864661654135,
      "loss": 0.0226,
      "step": 19525
    },
    {
      "epoch": 146.99,
      "learning_rate": 0.00015902255639097744,
      "loss": 0.0214,
      "step": 19550
    },
    {
      "epoch": 147.18,
      "learning_rate": 0.00015845864661654136,
      "loss": 0.0177,
      "step": 19575
    },
    {
      "epoch": 147.37,
      "learning_rate": 0.00015789473684210524,
      "loss": 0.0204,
      "step": 19600
    },
    {
      "epoch": 147.56,
      "learning_rate": 0.00015733082706766917,
      "loss": 0.0206,
      "step": 19625
    },
    {
      "epoch": 147.74,
      "learning_rate": 0.0001567669172932331,
      "loss": 0.0206,
      "step": 19650
    },
    {
      "epoch": 147.93,
      "learning_rate": 0.00015620300751879697,
      "loss": 0.021,
      "step": 19675
    },
    {
      "epoch": 148.12,
      "learning_rate": 0.0001556390977443609,
      "loss": 0.0217,
      "step": 19700
    },
    {
      "epoch": 148.31,
      "learning_rate": 0.0001550751879699248,
      "loss": 0.0191,
      "step": 19725
    },
    {
      "epoch": 148.5,
      "learning_rate": 0.0001545112781954887,
      "loss": 0.0189,
      "step": 19750
    },
    {
      "epoch": 148.68,
      "learning_rate": 0.00015394736842105263,
      "loss": 0.0199,
      "step": 19775
    },
    {
      "epoch": 148.87,
      "learning_rate": 0.00015338345864661653,
      "loss": 0.023,
      "step": 19800
    },
    {
      "epoch": 149.06,
      "learning_rate": 0.00015281954887218045,
      "loss": 0.0199,
      "step": 19825
    },
    {
      "epoch": 149.25,
      "learning_rate": 0.00015225563909774436,
      "loss": 0.0198,
      "step": 19850
    },
    {
      "epoch": 149.44,
      "learning_rate": 0.00015169172932330826,
      "loss": 0.0199,
      "step": 19875
    },
    {
      "epoch": 149.62,
      "learning_rate": 0.00015112781954887218,
      "loss": 0.0196,
      "step": 19900
    },
    {
      "epoch": 149.81,
      "learning_rate": 0.00015056390977443606,
      "loss": 0.0221,
      "step": 19925
    },
    {
      "epoch": 150.0,
      "learning_rate": 0.00015,
      "loss": 0.0217,
      "step": 19950
    },
    {
      "epoch": 150.19,
      "learning_rate": 0.0001494360902255639,
      "loss": 0.0173,
      "step": 19975
    },
    {
      "epoch": 150.38,
      "learning_rate": 0.0001488721804511278,
      "loss": 0.0187,
      "step": 20000
    },
    {
      "epoch": 150.38,
      "eval_bleu": 0.5631,
      "eval_gen_len": 11.5174,
      "eval_loss": 9.392818450927734,
      "eval_runtime": 14.8287,
      "eval_samples_per_second": 91.242,
      "eval_steps_per_second": 1.484,
      "step": 20000
    }
  ],
  "logging_steps": 25,
  "max_steps": 26600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 200,
  "save_steps": 20000,
  "total_flos": 4.79225015672832e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
